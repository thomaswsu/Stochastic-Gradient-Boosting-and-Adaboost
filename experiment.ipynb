{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "import glob\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = \"./data/data/data\"\n",
    "\n",
    "def load():\n",
    "    file_list = glob.glob(IMAGE_DIR + \"/*.jpg\")\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for fname in file_list:\n",
    "        with Image.open(fname) as img:\n",
    "            np_img = np.array(img).flatten()\n",
    "        label = int(os.path.split(fname)[-1].split('.')[0].split('_')[3])-1\n",
    "\n",
    "        X.append(np_img)\n",
    "        tempy = np.zeros(15)\n",
    "        tempy[label] = 1\n",
    "        Y.append(tempy)\n",
    "    X, Y = np.array(X), np.array(Y)\n",
    "    return(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "791 datapoints have classification 0\n",
      "806 datapoints have classification 1\n",
      "812 datapoints have classification 2\n",
      "806 datapoints have classification 3\n",
      "798 datapoints have classification 4\n",
      "781 datapoints have classification 5\n",
      "805 datapoints have classification 6\n",
      "832 datapoints have classification 7\n",
      "814 datapoints have classification 8\n",
      "785 datapoints have classification 9\n",
      "792 datapoints have classification 10\n",
      "799 datapoints have classification 11\n",
      "781 datapoints have classification 12\n",
      "800 datapoints have classification 13\n",
      "798 datapoints have classification 14\n"
     ]
    }
   ],
   "source": [
    "# create test, train split\n",
    "X, Y = load()\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, train_size=0.8, random_state=2021)\n",
    "Ytrain_classes = []\n",
    "for i in range(Ytrain.shape[1]):\n",
    "    Ytrain_0 = classify(Ytrain, i)\n",
    "    Ytrain_classes.append(Ytrain_0)\n",
    "    print(f\"{Ytrain_0.count(1)} datapoints have classification {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(weights, best):\n",
    "    def f(x):\n",
    "        return 1/2*(1/(1-best.error_rate)) * x if x in best.miss_data else 1/2*(1/best.error_rate) * x\n",
    "    return np.array(map(f,weights)).tolist()\n",
    "\n",
    "def run(Weak_Learners, data, eval_set, H, weights):\n",
    "    for wl in Weak_Learners:\n",
    "        wl.miss_classify(data, eval_set)\n",
    "        wl.calc_error_rate(weights)\n",
    "    \n",
    "    best = Weak_Learners[0]\n",
    "    for wl in Weak_Learners:\n",
    "        if wl.error_rate < best.error_rate:\n",
    "            best = wl\n",
    "    \n",
    "    best.calc_voting_power()\n",
    "    H.append(best)\n",
    "    \n",
    "    weights = update_weights(weights, best)\n",
    "    \n",
    "    accuracy = H_accuracy(H, data, eval_set)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy for class 0: 90.93%\n",
      "Training accuracy for class 1: 82.13%\n",
      "Training accuracy for class 2: 82.53%\n",
      "Training accuracy for class 3: 82.13%\n",
      "Training accuracy for class 4: 80.53%\n",
      "Training accuracy for class 5: 80.93%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Here we test the performace of our model with different amounts of training data \n",
    "TODO: METHOD OF CALCULATING ACCURACY MAY BE INCORRECT\n",
    "\"\"\"\n",
    "from time import time\n",
    "\n",
    "trainSizes = [x / 10 for x in range(1, 10, 1)] # Create a list of [0.1, 0.2, 0.3, ..., 0.9]\n",
    "\n",
    "hard_start = time()\n",
    "\n",
    "for trainRatio in trainSizes:\n",
    "    start = time()\n",
    "    \n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, train_size=trainRatio, random_state=2021)\n",
    "    Ytrain_classes = []\n",
    "    Ytest_classes = []\n",
    "    for i in range(Ytrain.shape[1]):\n",
    "        Ytrain_i = classify(Ytrain, i)\n",
    "        Ytrain_classes.append(Ytrain_i)\n",
    "        Ytest_i = classify(Ytest, i)\n",
    "        Ytest_classes.append(Ytest_i)\n",
    "    \n",
    "    accuracies = []\n",
    "    for i in range(Ytrain.shape[1]):\n",
    "        H = []\n",
    "        Weak_Learners = []\n",
    "        for _ in range(10):\n",
    "            model = ShallowTree()\n",
    "            model.fit(Xtrain, Ytrain_classes[0])\n",
    "            Weak_Learners.append(WeakLearner(model, 0))\n",
    "\n",
    "        weights = np.array([1/len(Xtrain) for _ in range(len(Xtrain))])\n",
    "        local_accuracies = []\n",
    "        for r in range(10):\n",
    "            local_accuracies.append(run(Weak_Learners, Xtrain, Ytrain_classes[i], H, weights))\n",
    "        accuracies.append(sum(local_accuracies)/len(local_accuracies))\n",
    "        training_accuracy = H_accuracy(H, Xtrain, Ytrain_classes[i])\n",
    "        print(f\"Training accuracy for class {i}: {training_accuracy:.2%}\")\n",
    "    #     WL.miss_classify(Xtrain, Ytrain_classes[0])\n",
    "    #     WL.calc_error_rate(np.array([1 for d in range(Xtrain.shape[0])]))\n",
    "    print(f\"Ratio: {trainRatio:.2%}\\n\\tAccuracy: {sum(accuracies)/len(accuracies):.2%}\")\n",
    "    print(f\"{time()-start:.2f} seconds elapsed\")\n",
    "print(f\"{time()-hard_start:.2f} seconds to run\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Now we vary the size of the trees\n",
    "\"\"\"\n",
    "# I had to do this because of import issues\n",
    "# TODO: Fix this so you don't have to redefine the function here\n",
    "def ShallowTree(d = 2): \n",
    "    return DecisionTreeClassifier(max_depth=d)\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, train_size=0.8, random_state=2021)\n",
    "Ytrain_classes = []\n",
    "for i in range(Ytrain.shape[1]):\n",
    "    Ytrain_0 = classify(Ytrain, i)\n",
    "    Ytrain_classes.append(Ytrain_0)\n",
    "\n",
    "for treeSize in range(2, 10):\n",
    "    Ytrain_classes = []\n",
    "    for i in range(Ytrain.shape[1]):\n",
    "        Ytrain_0 = classify(Ytrain, i)\n",
    "        Ytrain_classes.append(Ytrain_0)\n",
    "\n",
    "    model = ShallowTree(treeSize)\n",
    "    model.fit(Xtrain, Ytrain_classes[0])\n",
    "    WL = WeakLearner(model, 0)\n",
    "    WL.miss_classify(Xtrain, Ytrain_classes[0])\n",
    "    WL.calc_error_rate(np.array([1 for d in range(Xtrain.shape[0])]))\n",
    "    print(\"Percent correct with tree size {}: {}%\".format(treeSize, (WL.error_rate / Xtest.shape[0]) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

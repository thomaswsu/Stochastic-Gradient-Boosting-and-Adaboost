{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "import glob\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = \"./data/data/data\"\n",
    "\n",
    "def load():\n",
    "    file_list = glob.glob(IMAGE_DIR + \"/*.jpg\")\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for fname in file_list:\n",
    "        with Image.open(fname) as img:\n",
    "            np_img = np.array(img).flatten()\n",
    "        label = int(os.path.split(fname)[-1].split('.')[0].split('_')[3])-1\n",
    "\n",
    "        X.append(np_img)\n",
    "        tempy = np.zeros(15)\n",
    "        tempy[label] = 1\n",
    "        Y.append(tempy)\n",
    "    X, Y = np.array(X), np.array(Y)\n",
    "    return(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "794 datapoints have classification 0\n",
      "807 datapoints have classification 1\n",
      "790 datapoints have classification 2\n",
      "821 datapoints have classification 3\n",
      "770 datapoints have classification 4\n",
      "811 datapoints have classification 5\n",
      "784 datapoints have classification 6\n",
      "824 datapoints have classification 7\n",
      "799 datapoints have classification 8\n",
      "790 datapoints have classification 9\n",
      "788 datapoints have classification 10\n",
      "802 datapoints have classification 11\n",
      "815 datapoints have classification 12\n",
      "796 datapoints have classification 13\n",
      "809 datapoints have classification 14\n"
     ]
    }
   ],
   "source": [
    "# create test, train split\n",
    "X, Y = load()\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, train_size=0.8, random_state=2021)\n",
    "Ytrain_classes = []\n",
    "for i in range(Ytrain.shape[1]):\n",
    "    Ytrain_0 = classify(Ytrain, i)\n",
    "    Ytrain_classes.append(Ytrain_0)\n",
    "    print(f\"{Ytrain_0.count(1)} datapoints have classification {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Percent correct with 10.0% training, 90.0% testing: 0.5111111111111112%\n",
      "Percent correct with 20.0% training, 80.0% testing: 1.2583333333333333%\n",
      "Percent correct with 30.0% training, 70.0% testing: 2.276190476190476%\n",
      "Percent correct with 40.0% training, 60.0% testing: 3.6333333333333337%\n",
      "Percent correct with 50.0% training, 50.0% testing: 5.493333333333333%\n",
      "Percent correct with 60.0% training, 40.0% testing: 8.566666666666666%\n",
      "Percent correct with 70.0% training, 30.0% testing: 13.355555555555556%\n",
      "Percent correct with 80.0% training, 20.0% testing: 22.633333333333333%\n",
      "Percent correct with 90.0% training, 10.0% testing: 52.666666666666664%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Here we test the performace of our model with different amounts of training data \n",
    "TODO: METHOD OF CALCULATING ACCURACY MAY BE INCORRECT\n",
    "\"\"\"\n",
    "trainSizes = [x / 10 for x in range(1, 10, 1)] # Create a list of [0.1, 0.2, 0.3, ..., 0.9]\n",
    "\n",
    "for trainRatio in trainSizes:\n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, train_size=trainRatio, random_state=2021)\n",
    "    Ytrain_classes = []\n",
    "    for i in range(Ytrain.shape[1]):\n",
    "        Ytrain_0 = classify(Ytrain, i)\n",
    "        Ytrain_classes.append(Ytrain_0)\n",
    "\n",
    "    model = ShallowTree()\n",
    "    model.fit(Xtrain, Ytrain_classes[0])\n",
    "    WL = WeakLearner(model, 0)\n",
    "    WL.miss_classify(Xtrain, Ytrain_classes[0])\n",
    "    WL.calc_error_rate(np.array([1 for d in range(Xtrain.shape[0])]))\n",
    "    print(\"Percent correct with {}% training, {}% testing: {}%\".format(trainRatio * 100, 100 - (trainRatio * 100), (WL.error_rate / Xtest.shape[0]) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Percent correct with tree size 2: 22.633333333333333%\n",
      "Percent correct with tree size 3: 20.200000000000003%\n",
      "Percent correct with tree size 4: 16.066666666666666%\n",
      "Percent correct with tree size 5: 13.433333333333334%\n",
      "Percent correct with tree size 6: 10.233333333333333%\n",
      "Percent correct with tree size 7: 7.433333333333334%\n",
      "Percent correct with tree size 8: 6.033333333333333%\n",
      "Percent correct with tree size 9: 5.066666666666666%\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Now we vary the size of the trees\n",
    "\"\"\"\n",
    "# I had to do this because of import issues\n",
    "# TODO: Fix this so you don't have to redefine the function here\n",
    "def ShallowTree(d = 2): \n",
    "    return DecisionTreeClassifier(max_depth=d)\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, train_size=0.8, random_state=2021)\n",
    "Ytrain_classes = []\n",
    "for i in range(Ytrain.shape[1]):\n",
    "    Ytrain_0 = classify(Ytrain, i)\n",
    "    Ytrain_classes.append(Ytrain_0)\n",
    "\n",
    "for treeSize in range(2, 10):\n",
    "    Ytrain_classes = []\n",
    "    for i in range(Ytrain.shape[1]):\n",
    "        Ytrain_0 = classify(Ytrain, i)\n",
    "        Ytrain_classes.append(Ytrain_0)\n",
    "\n",
    "    model = ShallowTree(treeSize)\n",
    "    model.fit(Xtrain, Ytrain_classes[0])\n",
    "    WL = WeakLearner(model, 0)\n",
    "    WL.miss_classify(Xtrain, Ytrain_classes[0])\n",
    "    WL.calc_error_rate(np.array([1 for d in range(Xtrain.shape[0])]))\n",
    "    print(\"Percent correct with tree size {}: {}%\".format(treeSize, (WL.error_rate / Xtest.shape[0]) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "import glob\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE_DIR = \"./data/data/data\"\n",
    "\n",
    "# def load():\n",
    "#     file_list = glob.glob(IMAGE_DIR + \"/*.jpg\")\n",
    "#     X = []\n",
    "#     Y = []\n",
    "\n",
    "#     for fname in file_list:\n",
    "#         with Image.open(fname) as img:\n",
    "#             np_img = np.array(img).flatten()\n",
    "#         label = int(os.path.split(fname)[-1].split('.')[0].split('_')[3])-1\n",
    "\n",
    "#         X.append(np_img)\n",
    "#         tempy = np.zeros(15)\n",
    "#         tempy[label] = 1\n",
    "#         Y.append(tempy)\n",
    "#     X, Y = np.array(X), np.array(Y)\n",
    "#     return(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data\n",
    "# X, Y = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1024)\n",
      "(60000, 1)\n"
     ]
    }
   ],
   "source": [
    "(Xtrain,Ytrain),(Xtest,Ytest) = cifar10.load_data()\n",
    "X = np.append(Xtrain, Xtest, 0)\n",
    "Y = np.append(Ytrain, Ytest, 0)\n",
    "X = rgb2gray(X)\n",
    "X = X.reshape(X.shape[0], np.prod(X.shape[1:]))\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def WL_loss(H, Y, classifier):\n",
    "#     true_y = np.array(Y)\n",
    "#     y_size = true_y.shape[0]\n",
    "#     running = []\n",
    "#     print(true_y[classifier])\n",
    "#     for wl in H:\n",
    "#         val = 1 - (true_y[classifier].reshape(1, true_y[classifier].shape[0]) @ np.array(wl.y_pred))/len(wl.y_pred)\n",
    "#         running.append(max(0,val))\n",
    "#     return max(running)\n",
    "# #     return (sum([max(0, 1 - (true_y[classifier].reshape(1, true_y[classifier].shape[0]) @ np.array(wl.y_pred))/len(wl.y_pred)) for wl in H])/len(H))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import threading, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def update_weights(weights, best):\n",
    "#     def f(x):\n",
    "#         return 1/2*(1/(1-best.error_rate)) * x if x in best.miss_data else 1/2*(1/best.error_rate) * x\n",
    "#     return np.array(map(f,weights)).tolist()\n",
    "\n",
    "# def run(Weak_Learners, data, eval_set, H, weights):\n",
    "#     for wl in Weak_Learners:\n",
    "#         wl.fit(data, eval_set)\n",
    "#         wl.miss_classify(data, eval_set)\n",
    "#         wl.calc_error_rate(weights)\n",
    "    \n",
    "#     best = Weak_Learners[0]\n",
    "#     for wl in Weak_Learners:\n",
    "#         if wl.error_rate < best.error_rate:\n",
    "#             best = wl\n",
    "    \n",
    "#     best.calc_voting_power()\n",
    "#     H.append(best)\n",
    "    \n",
    "#     weights = update_weights(weights, best)\n",
    "    \n",
    "#     accuracy = H_accuracy(H, data, eval_set)\n",
    "    \n",
    "#     return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import threading, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "86.587%, 86.587%\n",
      "Average: 86.587%\n",
      "Class 6\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.200%, 87.200%, 87.200%, 87.200%, 87.200%, 87.200%, 87.200%, 87.200%, 87.200%, 87.200%\n",
      "Average: 87.200%\n",
      "        test:\n",
      "            86.160%, 86.160%, 86.160%, 86.160%, 86.160%, 86.160%, 86.160%, 86.160%, 86.160%, 86.160%\n",
      "Average: 86.160%\n",
      "Class 7\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.560%, 86.560%, 86.560%, 86.560%, 86.560%, 86.560%, 86.560%, 86.560%, 86.560%, 86.560%\n",
      "Average: 86.560%\n",
      "        test:\n",
      "            86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%\n",
      "Average: 86.267%\n",
      "Class 8\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.120%, 87.120%, 87.120%, 87.120%, 87.120%, 87.120%, 87.120%, 87.120%, 87.120%, 87.120%\n",
      "Average: 87.120%\n",
      "        test:\n",
      "            85.627%, 85.627%, 85.627%, 85.627%, 85.627%, 85.627%, 85.627%, 85.627%, 85.627%, 85.627%\n",
      "Average: 85.627%\n",
      "Class 9\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.827%, 86.827%, 86.827%, 86.827%, 86.827%, 86.827%, 86.827%, 86.827%, 86.827%, 86.827%\n",
      "Average: 86.827%\n",
      "        test:\n",
      "            86.640%, 86.640%, 86.640%, 86.640%, 86.640%, 86.640%, 86.640%, 86.640%, 86.640%, 86.640%\n",
      "Average: 86.640%\n",
      "Class 10\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.480%, 86.480%, 86.480%, 86.480%, 86.480%, 86.480%, 86.480%, 86.480%, 86.480%, 86.480%\n",
      "Average: 86.480%\n",
      "        test:\n",
      "            86.853%, 86.853%, 86.853%, 86.853%, 86.853%, 86.853%, 86.853%, 86.853%, 86.853%, 86.853%\n",
      "Average: 86.853%\n",
      "Class 11\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%\n",
      "Average: 86.667%\n",
      "        test:\n",
      "            86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%\n",
      "Average: 86.667%\n",
      "Class 12\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.320%, 86.320%, 86.320%, 86.320%, 86.320%, 86.320%, 86.320%, 86.320%, 86.320%, 86.320%\n",
      "Average: 86.320%\n",
      "        test:\n",
      "            87.013%, 87.013%, 87.013%, 87.013%, 87.013%, 87.013%, 87.013%, 87.013%, 87.013%, 87.013%\n",
      "Average: 87.013%\n",
      "Class 13\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.827%, 86.827%, 86.827%, 86.827%, 86.827%, 86.827%, 86.827%, 86.827%, 86.827%, 86.827%\n",
      "Average: 86.827%\n",
      "        test:\n",
      "            86.587%, 86.587%, 86.587%, 86.587%, 86.587%, 86.587%, 86.587%, 86.587%, 86.587%, 86.587%\n",
      "Average: 86.587%\n",
      "Class 14\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.227%, 87.227%, 87.227%, 87.227%, 87.227%, 87.227%, 87.227%, 87.227%, 87.227%, 87.227%\n",
      "Average: 87.227%\n",
      "        test:\n",
      "            87.147%, 87.147%, 87.147%, 87.147%, 87.147%, 87.147%, 87.147%, 87.147%, 87.147%, 87.147%\n",
      "Average: 87.147%\n",
      "Class 0\n",
      "    accuracies:\n",
      "        train:\n",
      "            88.578%, 88.578%, 88.578%, 88.578%, 88.578%, 88.578%, 88.578%, 88.578%, 88.578%, 88.578%\n",
      "Average: 88.578%\n",
      "        test:\n",
      "            87.567%, 87.567%, 87.567%, 87.567%, 87.567%, 87.567%, 87.567%, 87.567%, 87.567%, 87.567%\n",
      "Average: 87.567%\n",
      "Class 1\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.378%, 86.378%, 86.378%, 86.378%, 86.378%, 86.378%, 86.378%, 86.378%, 86.378%, 86.378%\n",
      "Average: 86.378%\n",
      "        test:\n",
      "            87.100%, 87.100%, 87.100%, 87.100%, 87.100%, 87.100%, 87.100%, 87.100%, 87.100%, 87.100%\n",
      "Average: 87.100%\n",
      "Class 2\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.356%, 86.356%, 86.356%, 86.356%, 86.356%, 86.356%, 86.356%, 86.356%, 86.356%, 86.356%\n",
      "Average: 86.356%\n",
      "        test:\n",
      "            87.133%, 87.133%, 87.133%, 87.133%, 87.133%, 87.133%, 87.133%, 87.133%, 87.133%, 87.133%\n",
      "Average: 87.133%\n",
      "Class 3\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.778%, 86.778%, 86.778%, 86.778%, 86.778%, 86.778%, 86.778%, 86.778%, 86.778%, 86.778%\n",
      "Average: 86.778%\n",
      "        test:\n",
      "            86.500%, 86.500%, 86.500%, 86.500%, 86.500%, 86.500%, 86.500%, 86.500%, 86.500%, 86.500%\n",
      "Average: 86.500%\n",
      "Class 4\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.533%, 87.533%, 87.533%, 87.533%, 87.533%, 87.533%, 87.533%, 87.533%, 87.533%, 87.533%\n",
      "Average: 87.533%\n",
      "        test:\n",
      "            86.300%, 86.300%, 86.300%, 86.300%, 86.300%, 86.300%, 86.300%, 86.300%, 86.300%, 86.300%\n",
      "Average: 86.300%\n",
      "Class 5\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.444%, 86.444%, 86.444%, 86.444%, 86.444%, 86.444%, 86.444%, 86.444%, 86.444%, 86.444%\n",
      "Average: 86.444%\n",
      "        test:\n",
      "            87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%\n",
      "Average: 87.000%\n",
      "Class 6\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%\n",
      "Average: 87.000%\n",
      "        test:\n",
      "            86.233%, 86.233%, 86.233%, 86.233%, 86.233%, 86.233%, 86.233%, 86.233%, 86.233%, 86.233%\n",
      "Average: 86.233%\n",
      "Class 7\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.489%, 86.489%, 86.489%, 86.489%, 86.489%, 86.489%, 86.489%, 86.489%, 86.489%, 86.489%\n",
      "Average: 86.489%\n",
      "        test:\n",
      "            86.933%, 86.933%, 86.933%, 86.933%, 86.933%, 86.933%, 86.933%, 86.933%, 86.933%, 86.933%\n",
      "Average: 86.933%\n",
      "Class 8\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.111%, 87.111%, 87.111%, 87.111%, 87.111%, 87.111%, 87.111%, 87.111%, 87.111%, 87.111%\n",
      "Average: 87.111%\n",
      "        test:\n",
      "            85.300%, 85.300%, 85.300%, 85.300%, 85.300%, 85.300%, 85.300%, 85.300%, 85.300%, 85.300%\n",
      "Average: 85.300%\n",
      "Class 9\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%\n",
      "Average: 87.000%\n",
      "        test:\n",
      "            86.200%, 86.200%, 86.200%, 86.200%, 86.200%, 86.200%, 86.200%, 86.200%, 86.200%, 86.200%\n",
      "Average: 86.200%\n",
      "Class 10\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.644%, 86.644%, 86.644%, 86.644%, 86.644%, 86.644%, 86.644%, 86.644%, 86.644%, 86.644%\n",
      "Average: 86.644%\n",
      "        test:\n",
      "            86.700%, 86.700%, 86.700%, 86.700%, 86.700%, 86.700%, 86.700%, 86.700%, 86.700%, 86.700%\n",
      "Average: 86.700%\n",
      "Class 11\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%\n",
      "Average: 86.667%\n",
      "        test:\n",
      "            86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%\n",
      "Average: 86.667%\n",
      "Class 12\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.333%, 86.333%, 86.333%, 86.333%, 86.333%, 86.333%, 86.333%, 86.333%, 86.333%, 86.333%\n",
      "Average: 86.333%\n",
      "        test:\n",
      "            87.167%, 87.167%, 87.167%, 87.167%, 87.167%, 87.167%, 87.167%, 87.167%, 87.167%, 87.167%\n",
      "Average: 87.167%\n",
      "Class 13\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.956%, 86.956%, 86.956%, 86.956%, 86.956%, 86.956%, 86.956%, 86.956%, 86.956%, 86.956%\n",
      "Average: 86.956%\n",
      "        test:\n",
      "            85.933%, 85.933%, 85.933%, 85.933%, 85.933%, 85.933%, 85.933%, 85.933%, 85.933%, 85.933%\n",
      "Average: 85.933%\n",
      "Class 14\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.467%, 86.467%, 86.467%, 86.467%, 86.467%, 86.467%, 86.467%, 86.467%, 86.467%, 86.467%\n",
      "Average: 86.467%\n",
      "        test:\n",
      "            86.967%, 86.967%, 86.967%, 86.967%, 86.967%, 86.967%, 86.967%, 86.967%, 86.967%, 86.967%\n",
      "Average: 86.967%\n",
      "Class 0\n",
      "    accuracies:\n",
      "        train:\n",
      "            88.552%, 88.552%, 88.552%, 88.552%, 88.552%, 88.552%, 88.552%, 88.552%, 88.552%, 88.552%\n",
      "Average: 88.552%\n",
      "        test:\n",
      "            86.222%, 86.222%, 86.222%, 86.222%, 86.222%, 86.222%, 86.222%, 86.222%, 86.222%, 86.222%\n",
      "Average: 86.222%\n",
      "Class 1\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.438%, 86.438%, 86.438%, 86.438%, 86.438%, 86.438%, 86.438%, 86.438%, 86.438%, 86.438%\n",
      "Average: 86.438%\n",
      "        test:\n",
      "            87.200%, 87.200%, 87.200%, 87.200%, 87.200%, 87.200%, 87.200%, 87.200%, 87.200%, 87.200%\n",
      "Average: 87.200%\n",
      "Class 2\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.705%, 86.705%, 86.705%, 86.705%, 86.705%, 86.705%, 86.705%, 86.705%, 86.705%, 86.705%\n",
      "Average: 86.705%\n",
      "        test:\n",
      "            86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%\n",
      "Average: 86.578%\n",
      "Class 3\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.610%, 86.610%, 86.610%, 86.610%, 86.610%, 86.610%, 86.610%, 86.610%, 86.610%, 86.610%\n",
      "Average: 86.610%\n",
      "        test:\n",
      "            87.289%, 87.289%, 87.289%, 87.289%, 87.289%, 87.289%, 87.289%, 87.289%, 87.289%, 87.289%\n",
      "Average: 87.289%\n",
      "Class 4\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.257%, 87.257%, 87.257%, 87.257%, 87.257%, 87.257%, 87.257%, 87.257%, 87.257%, 87.257%\n",
      "Average: 87.257%\n",
      "        test:\n",
      "            85.689%, 85.689%, 85.689%, 85.689%, 85.689%, 85.689%, 85.689%, 85.689%, 85.689%, 85.689%\n",
      "Average: 85.689%\n",
      "Class 5\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.362%, 86.362%, 86.362%, 86.362%, 86.362%, 86.362%, 86.362%, 86.362%, 86.362%, 86.362%\n",
      "Average: 86.362%\n",
      "        test:\n",
      "            87.378%, 87.378%, 87.378%, 87.378%, 87.378%, 87.378%, 87.378%, 87.378%, 87.378%, 87.378%\n",
      "Average: 87.378%\n",
      "Class 6\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.971%, 86.971%, 86.971%, 86.971%, 86.971%, 86.971%, 86.971%, 86.971%, 86.971%, 86.971%\n",
      "Average: 86.971%\n",
      "        test:\n",
      "            86.044%, 86.044%, 86.044%, 86.044%, 86.044%, 86.044%, 86.044%, 86.044%, 86.044%, 86.044%\n",
      "Average: 86.044%\n",
      "Class 7\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%\n",
      "Average: 86.267%\n",
      "        test:\n",
      "            87.600%, 87.600%, 87.600%, 87.600%, 87.600%, 87.600%, 87.600%, 87.600%, 87.600%, 87.600%\n",
      "Average: 87.600%\n",
      "Class 8\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.143%, 87.143%, 87.143%, 87.143%, 87.143%, 87.143%, 87.143%, 87.143%, 87.143%, 87.143%\n",
      "Average: 87.143%\n",
      "        test:\n",
      "            85.556%, 85.556%, 85.556%, 85.556%, 85.556%, 85.556%, 85.556%, 85.556%, 85.556%, 85.556%\n",
      "Average: 85.556%\n",
      "Class 9\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.895%, 86.895%, 86.895%, 86.895%, 86.895%, 86.895%, 86.895%, 86.895%, 86.895%, 86.895%\n",
      "Average: 86.895%\n",
      "        test:\n",
      "            86.133%, 86.133%, 86.133%, 86.133%, 86.133%, 86.133%, 86.133%, 86.133%, 86.133%, 86.133%\n",
      "Average: 86.133%\n",
      "Class 10\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.705%, 86.705%, 86.705%, 86.705%, 86.705%, 86.705%, 86.705%, 86.705%, 86.705%, 86.705%\n",
      "Average: 86.705%\n",
      "        test:\n",
      "            86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%\n",
      "Average: 86.578%\n",
      "Class 11\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.495%, 86.495%, 86.495%, 86.495%, 86.495%, 86.495%, 86.495%, 86.495%, 86.495%, 86.495%\n",
      "Average: 86.495%\n",
      "        test:\n",
      "            87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%\n",
      "Average: 87.067%\n",
      "Class 12\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.514%, 86.514%, 86.514%, 86.514%, 86.514%, 86.514%, 86.514%, 86.514%, 86.514%, 86.514%\n",
      "Average: 86.514%\n",
      "        test:\n",
      "            87.022%, 87.022%, 87.022%, 87.022%, 87.022%, 87.022%, 87.022%, 87.022%, 87.022%, 87.022%\n",
      "Average: 87.022%\n",
      "Class 13\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.048%, 87.048%, 87.048%, 87.048%, 87.048%, 87.048%, 87.048%, 87.048%, 87.048%, 87.048%\n",
      "Average: 87.048%\n",
      "        test:\n",
      "            85.822%, 85.822%, 85.822%, 85.822%, 85.822%, 85.822%, 85.822%, 85.822%, 85.822%, 85.822%\n",
      "Average: 85.822%\n",
      "Class 14\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.495%, 86.495%, 86.495%, 86.495%, 86.495%, 86.495%, 86.495%, 86.495%, 86.495%, 86.495%\n",
      "Average: 86.495%\n",
      "        test:\n",
      "            87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%\n",
      "Average: 87.067%\n",
      "Class 0\n",
      "    accuracies:\n",
      "        train:\n",
      "            88.683%, 88.683%, 88.683%, 88.683%, 88.683%, 88.683%, 88.683%, 88.683%, 88.683%, 88.683%\n",
      "Average: 88.683%\n",
      "        test:\n",
      "            87.733%, 87.733%, 87.733%, 87.733%, 87.733%, 87.733%, 87.733%, 87.733%, 87.733%, 87.733%\n",
      "Average: 87.733%\n",
      "Class 1\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.567%, 86.567%, 86.567%, 86.567%, 86.567%, 86.567%, 86.567%, 86.567%, 86.567%, 86.567%\n",
      "Average: 86.567%\n",
      "        test:\n",
      "            87.133%, 87.133%, 87.133%, 87.133%, 87.133%, 87.133%, 87.133%, 87.133%, 87.133%, 87.133%\n",
      "Average: 87.133%\n",
      "Class 2\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.883%, 86.883%, 86.883%, 86.883%, 86.883%, 86.883%, 86.883%, 86.883%, 86.883%, 86.883%\n",
      "Average: 86.883%\n",
      "        test:\n",
      "            85.933%, 85.933%, 85.933%, 85.933%, 85.933%, 85.933%, 85.933%, 85.933%, 85.933%, 85.933%\n",
      "Average: 85.933%\n",
      "Class 3\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.483%, 86.483%, 86.483%, 86.483%, 86.483%, 86.483%, 86.483%, 86.483%, 86.483%, 86.483%\n",
      "Average: 86.483%\n",
      "        test:\n",
      "            88.133%, 88.133%, 88.133%, 88.133%, 88.133%, 88.133%, 88.133%, 88.133%, 88.133%, 88.133%\n",
      "Average: 88.133%\n",
      "Class 4\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.533%, 87.533%, 87.533%, 87.533%, 87.533%, 87.533%, 87.533%, 87.533%, 87.533%, 87.533%\n",
      "Average: 87.533%\n",
      "        test:\n",
      "            85.067%, 85.067%, 85.067%, 85.067%, 85.067%, 85.067%, 85.067%, 85.067%, 85.067%, 85.067%\n",
      "Average: 85.067%\n",
      "Class 5\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.483%, 86.483%, 86.483%, 86.483%, 86.483%, 86.483%, 86.483%, 86.483%, 86.483%, 86.483%\n",
      "Average: 86.483%\n",
      "        test:\n",
      "            87.400%, 87.400%, 87.400%, 87.400%, 87.400%, 87.400%, 87.400%, 87.400%, 87.400%, 87.400%\n",
      "Average: 87.400%\n",
      "Class 6\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.967%, 86.967%, 86.967%, 86.967%, 86.967%, 86.967%, 86.967%, 86.967%, 86.967%, 86.967%\n",
      "Average: 86.967%\n",
      "        test:\n",
      "            85.533%, 85.533%, 85.533%, 85.533%, 85.533%, 85.533%, 85.533%, 85.533%, 85.533%, 85.533%\n",
      "Average: 85.533%\n",
      "Class 7\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%\n",
      "Average: 86.267%\n",
      "        test:\n",
      "            88.267%, 88.267%, 88.267%, 88.267%, 88.267%, 88.267%, 88.267%, 88.267%, 88.267%, 88.267%\n",
      "Average: 88.267%\n",
      "Class 8\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.817%, 86.817%, 86.817%, 86.817%, 86.817%, 86.817%, 86.817%, 86.817%, 86.817%, 86.817%\n",
      "Average: 86.817%\n",
      "        test:\n",
      "            86.200%, 86.200%, 86.200%, 86.200%, 86.200%, 86.200%, 86.200%, 86.200%, 86.200%, 86.200%\n",
      "Average: 86.200%\n",
      "Class 9\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.833%, 86.833%, 86.833%, 86.833%, 86.833%, 86.833%, 86.833%, 86.833%, 86.833%, 86.833%\n",
      "Average: 86.833%\n",
      "        test:\n",
      "            86.000%, 86.000%, 86.000%, 86.000%, 86.000%, 86.000%, 86.000%, 86.000%, 86.000%, 86.000%\n",
      "Average: 86.000%\n",
      "Class 10\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.867%, 86.867%, 86.867%, 86.867%, 86.867%, 86.867%, 86.867%, 86.867%, 86.867%, 86.867%\n",
      "Average: 86.867%\n",
      "        test:\n",
      "            85.867%, 85.867%, 85.867%, 85.867%, 85.867%, 85.867%, 85.867%, 85.867%, 85.867%, 85.867%\n",
      "Average: 85.867%\n",
      "Class 11\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.633%, 86.633%, 86.633%, 86.633%, 86.633%, 86.633%, 86.633%, 86.633%, 86.633%, 86.633%\n",
      "Average: 86.633%\n",
      "        test:\n",
      "            86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%\n",
      "Average: 86.800%\n",
      "Class 12\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.417%, 86.417%, 86.417%, 86.417%, 86.417%, 86.417%, 86.417%, 86.417%, 86.417%, 86.417%\n",
      "Average: 86.417%\n",
      "        test:\n",
      "            87.667%, 87.667%, 87.667%, 87.667%, 87.667%, 87.667%, 87.667%, 87.667%, 87.667%, 87.667%\n",
      "Average: 87.667%\n",
      "Class 13\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.817%, 86.817%, 86.817%, 86.817%, 86.817%, 86.817%, 86.817%, 86.817%, 86.817%, 86.817%\n",
      "Average: 86.817%\n",
      "        test:\n",
      "            86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%\n",
      "Average: 86.267%\n",
      "Class 14\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.517%, 86.517%, 86.517%, 86.517%, 86.517%, 86.517%, 86.517%, 86.517%, 86.517%, 86.517%\n",
      "Average: 86.517%\n",
      "        test:\n",
      "            87.267%, 87.267%, 87.267%, 87.267%, 87.267%, 87.267%, 87.267%, 87.267%, 87.267%, 87.267%\n",
      "Average: 87.267%\n",
      "Class 0\n",
      "    accuracies:\n",
      "        train:\n",
      "            88.296%, 88.296%, 88.296%, 88.296%, 88.296%, 88.296%, 88.296%, 88.296%, 88.296%, 88.296%\n",
      "Average: 88.296%\n",
      "        test:\n",
      "            88.400%, 88.400%, 88.400%, 88.400%, 88.400%, 88.400%, 88.400%, 88.400%, 88.400%, 88.400%\n",
      "Average: 88.400%\n",
      "Class 1\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.533%, 86.533%, 86.533%, 86.533%, 86.533%, 86.533%, 86.533%, 86.533%, 86.533%, 86.533%\n",
      "Average: 86.533%\n",
      "        test:\n",
      "            88.000%, 88.000%, 88.000%, 88.000%, 88.000%, 88.000%, 88.000%, 88.000%, 88.000%, 88.000%\n",
      "Average: 88.000%\n",
      "Class 2\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%\n",
      "Average: 86.667%\n",
      "        test:\n",
      "            86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%\n",
      "Average: 86.667%\n",
      "Class 3\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%\n",
      "Average: 86.652%\n",
      "        test:\n",
      "            87.867%, 87.867%, 87.867%, 87.867%, 87.867%, 87.867%, 87.867%, 87.867%, 87.867%, 87.867%\n",
      "Average: 87.867%\n",
      "Class 4\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.230%, 87.230%, 87.230%, 87.230%, 87.230%, 87.230%, 87.230%, 87.230%, 87.230%, 87.230%\n",
      "Average: 87.230%\n",
      "        test:\n",
      "            85.333%, 85.333%, 85.333%, 85.333%, 85.333%, 85.333%, 85.333%, 85.333%, 85.333%, 85.333%\n",
      "Average: 85.333%\n",
      "Class 5\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%\n",
      "Average: 86.578%\n",
      "        test:\n",
      "            87.467%, 87.467%, 87.467%, 87.467%, 87.467%, 87.467%, 87.467%, 87.467%, 87.467%, 87.467%\n",
      "Average: 87.467%\n",
      "Class 6\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%\n",
      "Average: 87.067%\n",
      "        test:\n",
      "            83.333%, 83.333%, 83.333%, 83.333%, 83.333%, 83.333%, 83.333%, 83.333%, 83.333%, 83.333%\n",
      "Average: 83.333%\n",
      "Class 7\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.400%, 86.400%, 86.400%, 86.400%, 86.400%, 86.400%, 86.400%, 86.400%, 86.400%, 86.400%\n",
      "Average: 86.400%\n",
      "        test:\n",
      "            89.067%, 89.067%, 89.067%, 89.067%, 89.067%, 89.067%, 89.067%, 89.067%, 89.067%, 89.067%\n",
      "Average: 89.067%\n",
      "Class 8\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%\n",
      "Average: 86.652%\n",
      "        test:\n",
      "            86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%\n",
      "Average: 86.800%\n",
      "Class 9\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.874%, 86.874%, 86.874%, 86.874%, 86.874%, 86.874%, 86.874%, 86.874%, 86.874%, 86.874%\n",
      "Average: 86.874%\n",
      "        test:\n",
      "            84.800%, 84.800%, 84.800%, 84.800%, 84.800%, 84.800%, 84.800%, 84.800%, 84.800%, 84.800%\n",
      "Average: 84.800%\n",
      "Class 10\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.711%, 86.711%, 86.711%, 86.711%, 86.711%, 86.711%, 86.711%, 86.711%, 86.711%, 86.711%\n",
      "Average: 86.711%\n",
      "        test:\n",
      "            86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%\n",
      "Average: 86.267%\n",
      "Class 11\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.681%, 86.681%, 86.681%, 86.681%, 86.681%, 86.681%, 86.681%, 86.681%, 86.681%, 86.681%\n",
      "Average: 86.681%\n",
      "        test:\n",
      "            86.533%, 86.533%, 86.533%, 86.533%, 86.533%, 86.533%, 86.533%, 86.533%, 86.533%, 86.533%\n",
      "Average: 86.533%\n",
      "Class 12\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%\n",
      "Average: 86.652%\n",
      "        test:\n",
      "            86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%\n",
      "Average: 86.800%\n",
      "Class 13\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.756%, 86.756%, 86.756%, 86.756%, 86.756%, 86.756%, 86.756%, 86.756%, 86.756%, 86.756%\n",
      "Average: 86.756%\n",
      "        test:\n",
      "            86.400%, 86.400%, 86.400%, 86.400%, 86.400%, 86.400%, 86.400%, 86.400%, 86.400%, 86.400%\n",
      "Average: 86.400%\n",
      "Class 14\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.415%, 86.415%, 86.415%, 86.415%, 86.415%, 86.415%, 86.415%, 86.415%, 86.415%, 86.415%\n",
      "Average: 86.415%\n",
      "        test:\n",
      "            88.933%, 88.933%, 88.933%, 88.933%, 88.933%, 88.933%, 88.933%, 88.933%, 88.933%, 88.933%\n",
      "Average: 88.933%\n"
     ]
    }
   ],
   "source": [
    "# from time import time\n",
    "\n",
    "# trainSizes = [x/10 for x in range(1,10)]\n",
    "# hard_start = time()\n",
    "\n",
    "# def print_dict(dictionary, sep=''):\n",
    "#     for key in dictionary.keys():\n",
    "#         new_sep = sep+'    '\n",
    "#         if type(key) is int:\n",
    "#             print(f\"Class {key}\")\n",
    "#         else:\n",
    "#             print(f\"{sep}{key}:\")\n",
    "#         if type(dictionary[key]) is dict:\n",
    "#             print_dict(dictionary[key], sep=new_sep)\n",
    "#         elif key == \"losses\":\n",
    "#             val_str = \"\"\n",
    "#             for i in range(len(dictionary[key])-1):\n",
    "#                 val_str += f\"{dictionary[key][i]:.2f}, \"\n",
    "#             val_str += f\"{dictionary[key][-1]:.2f}\"\n",
    "#             print(f\"{new_sep}{val_str}\")\n",
    "#             print(f\"Average: {sum(dictionary[key])/len(dictionary[key]):.2f}\")\n",
    "#         elif type(dictionary[key]) is list:\n",
    "#             val_str = \"\"\n",
    "#             for i in range(len(dictionary[key])-1):\n",
    "#                 val_str += f\"{dictionary[key][i]:.3%}, \"\n",
    "#             val_str += f\"{dictionary[key][-1]:.3%}\"\n",
    "#             print(f\"{new_sep}{val_str}\")\n",
    "#             print(f\"Average: {sum(dictionary[key])/len(dictionary[key]):.3%}\")\n",
    "#         else:\n",
    "#             print(f\"{new_sep}{dictionary[key]}\")\n",
    "\n",
    "# def thread_loss(H, Y, classifier):\n",
    "#     true_y = np.array(Y)\n",
    "#     return (sum([max(0, 1 - (true_y.reshape(1, true_y.shape[0]) @ np.array(wl.y_pred))/len(wl.y_pred)) for wl in H])/len(H))[0]\n",
    "            \n",
    "# def runner(pnum, ptracker, rcount, Xtrain, Ytrain, Xtest, Ytest, classifier):\n",
    "#     H = []\n",
    "#     Weak_Learners = []\n",
    "#     for i in range(10):\n",
    "#         model = ShallowTree()\n",
    "#         Weak_Learners.append(WeakLearner(model, classifier))\n",
    "#     weights = np.array([1/len(Xtrain) for _ in range(len(Xtrain))])\n",
    "#     for r in range(10):\n",
    "#         ptracker[rcount][pnum][\"accuracies\"][\"train\"].append(run(Weak_Learners, Xtrain, Ytrain, H, weights))\n",
    "#         ptracker[rcount][pnum][\"losses\"].append(thread_loss(H, Ytrain, classifier))\n",
    "#         ptracker[rcount][pnum][\"accuracies\"][\"test\"].append(H_accuracy(H, Xtest, Ytest))\n",
    "\n",
    "# def f(pnum, ptracker, rcount, split, X, Y):\n",
    "#     for i in range(pnum):\n",
    "#         ptracker[rcount][i] = {}\n",
    "#         ptracker[rcount][i][\"accuracies\"] = {\"train\": [], \"test\": []}\n",
    "#         ptracker[rcount][i][\"losses\"] = []\n",
    "#     Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, train_size=split, random_state = 2021)\n",
    "#     Ytrain_classes = [classify(Ytrain, i) for i in range(15)]\n",
    "#     Ytest_classes = [classify(Ytest, i) for i in range(15)]\n",
    "#     jobs = []\n",
    "#     for i in range(15):\n",
    "#         proc = threading.Thread(target=runner, args=(i, ptracker, rcount, Xtrain, Ytrain_classes[i], Xtest, Ytest_classes[i], i), name=f\"Thread {i}\")\n",
    "#         jobs.append(proc)\n",
    "#         proc.start()\n",
    "    \n",
    "#     for count,p in enumerate(jobs):\n",
    "#         p.join()\n",
    "\n",
    "# ptrackers = [{} for _ in trainSizes]\n",
    "# for i,ratio in enumerate(trainSizes):\n",
    "#     f(15, ptrackers, i, ratio, X, Y)\n",
    "# for i in range(len(ptrackers)):\n",
    "#     print(f\"Ratio: {trainSizes[i]}\")\n",
    "#     print_dict(ptrackers[i])\n",
    "# # ratio_threads = []\n",
    "# # for i,ratio in enumerate(trainSizes):\n",
    "# #     print(f\"Running ratio: {ratio:.0%}\")\n",
    "# #     proc = threading.Thread(target=f, args=(15, ptrackers, i, ratio, X, Y))\n",
    "# #     ratio_threads.append(proc)\n",
    "# #     proc.start()\n",
    "\n",
    "# # for i, proc in enumerate(ratio_threads):\n",
    "# #     proc.join()\n",
    "# #     print_dict(ptrackers[i])\n",
    "# print(f\"Took {time()-hard_start} seconds to run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here we test the performace of our model with different amounts of training data \n",
    "\"\"\"\n",
    "from time import time\n",
    "\n",
    "trainSizes = [x / 10 for x in range(1, 10, 1)] # Create a list of [0.5, ..., 0.9] If x < 0.5 we get an out of bounds error on the weights\n",
    "\n",
    "hard_start = time()\n",
    "\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "for trainRatio in trainSizes:\n",
    "    start = time()\n",
    "    \n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, train_size=trainRatio, random_state=2021)\n",
    "    Ytrain_classes = []\n",
    "    Ytest_classes = []\n",
    "    if Ytrain.shape[1] != 1:\n",
    "        for i in range(Ytrain.shape[1]):\n",
    "            Ytrain_i = classify(Ytrain, i)\n",
    "            Ytrain_classes.append(Ytrain_i)\n",
    "            Ytest_i = classify(Ytest, i)\n",
    "            Ytest_classes.append(Ytest_i)\n",
    "    else:\n",
    "        Ytrain_classes = Ytrain.copy()\n",
    "        Ytest_classes = Ytest.copy()\n",
    "    \n",
    "    model = Boost(n_estimators=100, base_learner=ShallowTree()).fit(Xtrain,Ytrain)\n",
    "    \n",
    "#     train_accuracies = []\n",
    "#     test_accuracies = []\n",
    "#     for i in range(Ytrain.shape[1]):\n",
    "#         H = []\n",
    "#         Weak_Learners = []\n",
    "#         for _ in range(10):\n",
    "#             model = ShallowTree()\n",
    "#             model.fit(Xtrain, Ytrain_classes[0])\n",
    "#             Weak_Learners.append(WeakLearner(model, 0))\n",
    "\n",
    "#         weights = np.array([1/len(Xtrain) for _ in range(len(Xtrain))])\n",
    "#         train_local_accuracies = []\n",
    "#         test_local_accuracies = []\n",
    "#         for r in range(10):\n",
    "#             train_local_accuracies.append(run(Weak_Learners, Xtrain, Ytrain_classes[i], H, weights))\n",
    "#             print(f\"Loss on run {r}: {WL_loss(H, Ytrain_classes, i):.3f}\")\n",
    "#             test_local_accuracies.append(H_accuracy(H, Xtest, Ytest_classes[i]))\n",
    "\n",
    "#         train_accuracies.append(sum(train_local_accuracies) / len(train_local_accuracies))\n",
    "#         test_accuracies.append(sum(test_local_accuracies)/len(test_local_accuracies))\n",
    "        \n",
    "    train_acc = model.accuracy(model.predict(Xtrain),Ytrain)\n",
    "    train_accuracy.append(train_acc)\n",
    "    print(f\"Ratio: {trainRatio:.2%}\\n\\t Train Accuracy: {train_acc:.2%}\")\n",
    "    test_acc = model.accuracy(model.predict(Xtest),Ytest)\n",
    "    test_accuracy.append(test_acc)\n",
    "    print(f\"Ratio: {trainRatio:.2%}\\n\\t Test Accuracy: {test_acc:.2%}\")\n",
    "    print(f\"{time()-start:.2f} seconds elapsed\")\n",
    "    \n",
    "print(f\"{time()-hard_start:.2f} seconds to run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Ytrain.shape)\n",
    "# print(Ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent correct with training set and tree size 2: 82.10%\n",
      "Percent correct with test set and tree size 2: 82.49%\n",
      "685.31 seconds elapsed\n",
      "Percent correct with training set and tree size 3: 81.15%\n",
      "Percent correct with test set and tree size 3: 81.34%\n",
      "770.76 seconds elapsed\n",
      "Percent correct with training set and tree size 4: 80.59%\n",
      "Percent correct with test set and tree size 4: 80.99%\n",
      "848.00 seconds elapsed\n",
      "Percent correct with training set and tree size 5: 80.21%\n",
      "Percent correct with test set and tree size 5: 80.79%\n",
      "872.08 seconds elapsed\n",
      "Percent correct with training set and tree size 6: 79.90%\n",
      "Percent correct with test set and tree size 6: 80.59%\n",
      "962.80 seconds elapsed\n",
      "Percent correct with training set and tree size 7: 79.61%\n",
      "Percent correct with test set and tree size 7: 80.38%\n",
      "1051.88 seconds elapsed\n",
      "Percent correct with training set and tree size 8: 79.32%\n",
      "Percent correct with test set and tree size 8: 80.17%\n",
      "1139.44 seconds elapsed\n",
      "Percent correct with training set and tree size 9: 79.07%\n",
      "Percent correct with test set and tree size 9: 79.97%\n",
      "1230.19 seconds elapsed\n",
      "7560.57 seconds to run\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Now we vary the size of the trees\n",
    "We use 80% train, 20% test (The standard)\n",
    "\"\"\"\n",
    "hard_start = time()\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, train_size=0.8, random_state=2021)\n",
    "Ytrain_classes = []\n",
    "Ytest_classes = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for treeSize in range(1, 10):\n",
    "    start = time()\n",
    "    if Ytrain.shape[1] != 1:\n",
    "        for i in range(Ytrain.shape[1]):\n",
    "            Ytrain_i = classify(Ytrain, i)\n",
    "            Ytrain_classes.append(Ytrain_i)\n",
    "            Ytest_i = classify(Ytest, i)\n",
    "            Ytest_classes.append(Ytest_i)\n",
    "    else:\n",
    "        Ytrain_classes = Ytrain.copy()\n",
    "        Ytest_classes = Ytest.copy()\n",
    "        \n",
    "    model = Boost(n_estimators=250, base_learner=ShallowTree(treeSize)).fit(Xtrain,Ytrain)\n",
    "        \n",
    "#     for i in range(Ytrain.shape[1]):\n",
    "#         H_train = []\n",
    "#         H_test =[]\n",
    "#         Weak_Learners = []\n",
    "#         for _ in range(10):\n",
    "#             model = ShallowTree(treeSize)\n",
    "#             model.fit(Xtrain, Ytrain_classes[0])\n",
    "#             Weak_Learners.append(WeakLearner(model, 0))\n",
    "\n",
    "#         weights = np.array([1/len(Xtrain) for _ in range(len(Xtrain))])\n",
    "#         local_accuracies = []\n",
    "        \n",
    "#         for r in range(10):\n",
    "#             train_local_accuracies.append(run(Weak_Learners, Xtrain, Ytrain_classes[i], H_train, weights))\n",
    "#             test_local_accuracies.append(run(Weak_Learners, Xtest, Ytest_classes[i], H_test, weights))\n",
    "\n",
    "#         train_accuracies.append(sum(train_local_accuracies) / len(train_local_accuracies))\n",
    "#         test_accuracies.append(sum(test_local_accuracies)/len(test_local_accuracies))\n",
    "\n",
    "    train_acc = model.accuracy(model.predict(Xtrain),Ytrain)\n",
    "    train_accuracies.append(train_acc)\n",
    "    test_acc = model.accuracy(model.predict(Xtest),Ytest)\n",
    "    test_accuracies.append(test_acc)\n",
    "\n",
    "    print(f\"Percent correct with training set and tree size {treeSize}: {train_acc:.2%}\")\n",
    "    print(f\"Percent correct with test set and tree size {treeSize}: {test_acc/len(test_accuracies):.2%}\")\n",
    "    print(f\"{time()-start:.2f} seconds elapsed\")\n",
    "print(f\"{time()-hard_start:.2f} seconds to run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

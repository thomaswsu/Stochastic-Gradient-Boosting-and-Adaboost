{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "import glob\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = \"./data/data/data\"\n",
    "\n",
    "def load():\n",
    "    file_list = glob.glob(IMAGE_DIR + \"/*.jpg\")\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for fname in file_list:\n",
    "        with Image.open(fname) as img:\n",
    "            np_img = np.array(img).flatten()\n",
    "        label = int(os.path.split(fname)[-1].split('.')[0].split('_')[3])-1\n",
    "\n",
    "        X.append(np_img)\n",
    "        tempy = np.zeros(15)\n",
    "        tempy[label] = 1\n",
    "        Y.append(tempy)\n",
    "    X, Y = np.array(X), np.array(Y)\n",
    "    return(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data\n",
    "X, Y = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WL_loss(H, Y, classifier):\n",
    "    true_y = np.array(Y)\n",
    "    return (sum([max(0, 1 - (true_y[classifier].reshape(1, true_y[classifier].shape[0]) @ np.array(wl.y_pred))/len(wl.y_pred)) for wl in H])/len(H))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(weights, best):\n",
    "    def f(x):\n",
    "        return 1/2*(1/(1-best.error_rate)) * x if x in best.miss_data else 1/2*(1/best.error_rate) * x\n",
    "    return np.array(map(f,weights)).tolist()\n",
    "\n",
    "def run(Weak_Learners, data, eval_set, H, weights):\n",
    "    for wl in Weak_Learners:\n",
    "        wl.miss_classify(data, eval_set)\n",
    "        wl.calc_error_rate(weights)\n",
    "    \n",
    "    best = Weak_Learners[0]\n",
    "    for wl in Weak_Learners:\n",
    "        if wl.error_rate < best.error_rate:\n",
    "            best = wl\n",
    "    \n",
    "    best.calc_voting_power()\n",
    "    H.append(best)\n",
    "    \n",
    "    weights = update_weights(weights, best)\n",
    "    \n",
    "    accuracy = H_accuracy(H, data, eval_set)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on run 0: 0.1810666666666667\n",
      "Loss on run 1: 0.1810666666666667\n",
      "Loss on run 2: 0.1810666666666667\n",
      "Loss on run 3: 0.1810666666666667\n",
      "Loss on run 4: 0.1810666666666667\n",
      "Loss on run 5: 0.1810666666666667\n",
      "Loss on run 6: 0.1810666666666667\n",
      "Loss on run 7: 0.1810666666666667\n",
      "Loss on run 8: 0.1810666666666667\n",
      "Loss on run 9: 0.1810666666666667\n",
      "Loss on run 0: 0.1850666666666667\n",
      "Loss on run 1: 0.1850666666666667\n",
      "Loss on run 2: 0.1850666666666667\n",
      "Loss on run 3: 0.1850666666666667\n",
      "Loss on run 4: 0.1850666666666667\n",
      "Loss on run 5: 0.1850666666666667\n",
      "Loss on run 6: 0.1850666666666667\n",
      "Loss on run 7: 0.1850666666666667\n",
      "Loss on run 8: 0.1850666666666667\n",
      "Loss on run 9: 0.1850666666666667\n",
      "Loss on run 0: 0.17600000000000005\n",
      "Loss on run 1: 0.17600000000000005\n",
      "Loss on run 2: 0.17600000000000005\n",
      "Loss on run 3: 0.17600000000000005\n",
      "Loss on run 4: 0.17600000000000005\n",
      "Loss on run 5: 0.17600000000000005\n",
      "Loss on run 6: 0.17600000000000002\n",
      "Loss on run 7: 0.17600000000000005\n",
      "Loss on run 8: 0.17600000000000005\n",
      "Loss on run 9: 0.17600000000000007\n",
      "Loss on run 0: 0.18186666666666662\n",
      "Loss on run 1: 0.18186666666666662\n",
      "Loss on run 2: 0.18186666666666662\n",
      "Loss on run 3: 0.18186666666666662\n",
      "Loss on run 4: 0.18186666666666662\n",
      "Loss on run 5: 0.18186666666666662\n",
      "Loss on run 6: 0.18186666666666662\n",
      "Loss on run 7: 0.18186666666666662\n",
      "Loss on run 8: 0.18186666666666662\n",
      "Loss on run 9: 0.18186666666666662\n",
      "Loss on run 0: 0.17413333333333336\n",
      "Loss on run 1: 0.17413333333333336\n",
      "Loss on run 2: 0.17413333333333336\n",
      "Loss on run 3: 0.17413333333333336\n",
      "Loss on run 4: 0.17413333333333336\n",
      "Loss on run 5: 0.17413333333333336\n",
      "Loss on run 6: 0.1741333333333334\n",
      "Loss on run 7: 0.17413333333333336\n",
      "Loss on run 8: 0.17413333333333336\n",
      "Loss on run 9: 0.17413333333333333\n",
      "Loss on run 0: 0.17066666666666663\n",
      "Loss on run 1: 0.17066666666666663\n",
      "Loss on run 2: 0.17066666666666663\n",
      "Loss on run 3: 0.17066666666666663\n",
      "Loss on run 4: 0.17066666666666663\n",
      "Loss on run 5: 0.17066666666666663\n",
      "Loss on run 6: 0.17066666666666666\n",
      "Loss on run 7: 0.17066666666666663\n",
      "Loss on run 8: 0.17066666666666663\n",
      "Loss on run 9: 0.1706666666666666\n",
      "Loss on run 0: 0.17413333333333336\n",
      "Loss on run 1: 0.17413333333333336\n",
      "Loss on run 2: 0.17413333333333336\n",
      "Loss on run 3: 0.17413333333333336\n",
      "Loss on run 4: 0.17413333333333336\n",
      "Loss on run 5: 0.17413333333333336\n",
      "Loss on run 6: 0.1741333333333334\n",
      "Loss on run 7: 0.17413333333333336\n",
      "Loss on run 8: 0.17413333333333336\n",
      "Loss on run 9: 0.17413333333333333\n",
      "Loss on run 0: 0.1824\n",
      "Loss on run 1: 0.1824\n",
      "Loss on run 2: 0.1824\n",
      "Loss on run 3: 0.1824\n",
      "Loss on run 4: 0.1824\n",
      "Loss on run 5: 0.1824\n",
      "Loss on run 6: 0.18240000000000003\n",
      "Loss on run 7: 0.1824\n",
      "Loss on run 8: 0.1824\n",
      "Loss on run 9: 0.18239999999999998\n",
      "Loss on run 0: 0.18159999999999998\n",
      "Loss on run 1: 0.18159999999999998\n",
      "Loss on run 2: 0.18159999999999998\n",
      "Loss on run 3: 0.18159999999999998\n",
      "Loss on run 4: 0.18159999999999998\n",
      "Loss on run 5: 0.18159999999999998\n",
      "Loss on run 6: 0.18159999999999998\n",
      "Loss on run 7: 0.18159999999999998\n",
      "Loss on run 8: 0.18159999999999998\n",
      "Loss on run 9: 0.18159999999999998\n",
      "Loss on run 0: 0.17600000000000005\n",
      "Loss on run 1: 0.17600000000000005\n",
      "Loss on run 2: 0.17600000000000005\n",
      "Loss on run 3: 0.17600000000000005\n",
      "Loss on run 4: 0.17600000000000005\n",
      "Loss on run 5: 0.17600000000000005\n",
      "Loss on run 6: 0.17600000000000002\n",
      "Loss on run 7: 0.17600000000000005\n",
      "Loss on run 8: 0.17600000000000005\n",
      "Loss on run 9: 0.17600000000000007\n",
      "Loss on run 0: 0.18400000000000005\n",
      "Loss on run 1: 0.18400000000000005\n",
      "Loss on run 2: 0.18400000000000005\n",
      "Loss on run 3: 0.18400000000000005\n",
      "Loss on run 4: 0.18400000000000005\n",
      "Loss on run 5: 0.18400000000000005\n",
      "Loss on run 6: 0.18400000000000002\n",
      "Loss on run 7: 0.18400000000000005\n",
      "Loss on run 8: 0.18400000000000005\n",
      "Loss on run 9: 0.18400000000000008\n",
      "Loss on run 0: 0.18266666666666664\n",
      "Loss on run 1: 0.18266666666666664\n",
      "Loss on run 2: 0.18266666666666664\n",
      "Loss on run 3: 0.18266666666666664\n",
      "Loss on run 4: 0.18266666666666664\n",
      "Loss on run 5: 0.18266666666666664\n",
      "Loss on run 6: 0.18266666666666667\n",
      "Loss on run 7: 0.18266666666666664\n",
      "Loss on run 8: 0.18266666666666664\n",
      "Loss on run 9: 0.18266666666666662\n",
      "Loss on run 0: 0.17733333333333334\n",
      "Loss on run 1: 0.17733333333333334\n",
      "Loss on run 2: 0.17733333333333334\n",
      "Loss on run 3: 0.17733333333333334\n",
      "Loss on run 4: 0.17733333333333334\n",
      "Loss on run 5: 0.17733333333333334\n",
      "Loss on run 6: 0.17733333333333334\n",
      "Loss on run 7: 0.17733333333333334\n",
      "Loss on run 8: 0.17733333333333334\n",
      "Loss on run 9: 0.17733333333333334\n",
      "Loss on run 0: 0.1802666666666667\n",
      "Loss on run 1: 0.1802666666666667\n",
      "Loss on run 2: 0.1802666666666667\n",
      "Loss on run 3: 0.1802666666666667\n",
      "Loss on run 4: 0.1802666666666667\n",
      "Loss on run 5: 0.1802666666666667\n",
      "Loss on run 6: 0.18026666666666666\n",
      "Loss on run 7: 0.1802666666666667\n",
      "Loss on run 8: 0.1802666666666667\n",
      "Loss on run 9: 0.18026666666666671\n",
      "Loss on run 0: 0.1757333333333333\n",
      "Loss on run 1: 0.1757333333333333\n",
      "Loss on run 2: 0.1757333333333333\n",
      "Loss on run 3: 0.1757333333333333\n",
      "Loss on run 4: 0.1757333333333333\n",
      "Loss on run 5: 0.1757333333333333\n",
      "Loss on run 6: 0.1757333333333333\n",
      "Loss on run 7: 0.1757333333333333\n",
      "Loss on run 8: 0.1757333333333333\n",
      "Loss on run 9: 0.1757333333333333\n",
      "Ratio: 50.00%\n",
      "\t Train Accuracy: 81.56%\n",
      "Ratio: 50.00%\n",
      "\t Test Accuracy: 82.11%\n",
      "855.95 seconds elapsed\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 6000 is different from 9000)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-c90f23714b14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mtrain_local_accuracies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWeak_Learners\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtrain_classes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0mtest_local_accuracies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWeak_Learners\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtest_classes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Loss on run {r}: {WL_loss(H_train, Ytrain_classes, i)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mtrain_accuracies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_local_accuracies\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_local_accuracies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-b17b275118e3>\u001b[0m in \u001b[0;36mWL_loss\u001b[1;34m(H, Y, classifier)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mWL_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mtrue_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrue_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mwl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-b17b275118e3>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mWL_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mtrue_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrue_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mwl\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 6000 is different from 9000)"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Here we test the performace of our model with different amounts of training data \n",
    "\"\"\"\n",
    "from time import time\n",
    "\n",
    "trainSizes = [x / 10 for x in range(5, 10, 1)] # Create a list of [0.5, ..., 0.9] If x < 0.5 we get an out of bounds error on the weights\n",
    "\n",
    "hard_start = time()\n",
    "\n",
    "for trainRatio in trainSizes:\n",
    "    start = time()\n",
    "    \n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, train_size=trainRatio, random_state=2021)\n",
    "    Ytrain_classes = []\n",
    "    Ytest_classes = []\n",
    "    for i in range(Ytrain.shape[1]):\n",
    "        Ytrain_i = classify(Ytrain, i)\n",
    "        Ytrain_classes.append(Ytrain_i)\n",
    "        Ytest_i = classify(Ytest, i)\n",
    "        Ytest_classes.append(Ytest_i)\n",
    "    \n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "    for i in range(Ytrain.shape[1]):\n",
    "        H_train = []\n",
    "        H_test = []\n",
    "        Weak_Learners = []\n",
    "        for _ in range(10):\n",
    "            model = ShallowTree()\n",
    "            model.fit(Xtrain, Ytrain_classes[0])\n",
    "            Weak_Learners.append(WeakLearner(model, 0))\n",
    "\n",
    "        weights = np.array([1/len(Xtrain) for _ in range(len(Xtrain))])\n",
    "        train_local_accuracies = []\n",
    "        test_local_accuracies = []\n",
    "        for r in range(10):\n",
    "            train_local_accuracies.append(run(Weak_Learners, Xtrain, Ytrain_classes[i], H_train, weights))\n",
    "            print(f\"Loss on run {r:.2f}: {WL_loss(H_train, Ytrain_classes, i)}\")\n",
    "            test_local_accuracies.append(run(Weak_Learners, Xtest, Ytest_classes[i], H_test, weights))\n",
    "\n",
    "        train_accuracies.append(sum(train_local_accuracies) / len(train_local_accuracies))\n",
    "        test_accuracies.append(sum(test_local_accuracies)/len(test_local_accuracies))\n",
    "        \n",
    "\n",
    "    print(f\"Ratio: {trainRatio:.2%}\\n\\t Train Accuracy: {sum(train_accuracies)/len(train_accuracies):.2%}\")\n",
    "    print(f\"Ratio: {trainRatio:.2%}\\n\\t Test Accuracy: {sum(test_accuracies)/len(test_accuracies):.2%}\")\n",
    "    print(f\"{time()-start:.2f} seconds elapsed\")\n",
    "    \n",
    "print(f\"{time()-hard_start:.2f} seconds to run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13500, 15)\n",
      "(1500, 15)\n"
     ]
    }
   ],
   "source": [
    "print(Ytrain.shape)\n",
    "print(Ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent correct with training set and tree size 2: 82.10%\n",
      "Percent correct with test set and tree size 2: 82.49%\n",
      "685.31 seconds elapsed\n",
      "Percent correct with training set and tree size 3: 81.15%\n",
      "Percent correct with test set and tree size 3: 81.34%\n",
      "770.76 seconds elapsed\n",
      "Percent correct with training set and tree size 4: 80.59%\n",
      "Percent correct with test set and tree size 4: 80.99%\n",
      "848.00 seconds elapsed\n",
      "Percent correct with training set and tree size 5: 80.21%\n",
      "Percent correct with test set and tree size 5: 80.79%\n",
      "872.08 seconds elapsed\n",
      "Percent correct with training set and tree size 6: 79.90%\n",
      "Percent correct with test set and tree size 6: 80.59%\n",
      "962.80 seconds elapsed\n",
      "Percent correct with training set and tree size 7: 79.61%\n",
      "Percent correct with test set and tree size 7: 80.38%\n",
      "1051.88 seconds elapsed\n",
      "Percent correct with training set and tree size 8: 79.32%\n",
      "Percent correct with test set and tree size 8: 80.17%\n",
      "1139.44 seconds elapsed\n",
      "Percent correct with training set and tree size 9: 79.07%\n",
      "Percent correct with test set and tree size 9: 79.97%\n",
      "1230.19 seconds elapsed\n",
      "7560.57 seconds to run\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Now we vary the size of the trees\n",
    "We use 80% train, 20% test (The standard)\n",
    "\"\"\"\n",
    "hard_start = time()\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, train_size=0.8, random_state=2021)\n",
    "Ytrain_classes = []\n",
    "Ytest_classes = []\n",
    "\n",
    "\n",
    "for treeSize in range(2, 10):\n",
    "    start = time()\n",
    "    for i in range(Ytrain.shape[1]):\n",
    "        Ytrain_i = classify(Ytrain, i)\n",
    "        Ytrain_classes.append(Ytrain_i)\n",
    "        Ytest_i = classify(Ytest, i)\n",
    "        Ytest_classes.append(Ytest_i)\n",
    "\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "    for i in range(Ytrain.shape[1]):\n",
    "        H_train = []\n",
    "        H_test =[]\n",
    "        Weak_Learners = []\n",
    "        for _ in range(10):\n",
    "            model = ShallowTree(treeSize)\n",
    "            model.fit(Xtrain, Ytrain_classes[0])\n",
    "            Weak_Learners.append(WeakLearner(model, 0))\n",
    "\n",
    "        weights = np.array([1/len(Xtrain) for _ in range(len(Xtrain))])\n",
    "        local_accuracies = []\n",
    "        \n",
    "        for r in range(10):\n",
    "            train_local_accuracies.append(run(Weak_Learners, Xtrain, Ytrain_classes[i], H_train, weights))\n",
    "            test_local_accuracies.append(run(Weak_Learners, Xtest, Ytest_classes[i], H_test, weights))\n",
    "\n",
    "        train_accuracies.append(sum(train_local_accuracies) / len(train_local_accuracies))\n",
    "        test_accuracies.append(sum(test_local_accuracies)/len(test_local_accuracies))\n",
    "\n",
    "    print(f\"Percent correct with training set and tree size {treeSize}: {sum(train_accuracies)/len(train_accuracies):.2%}\")\n",
    "    print(f\"Percent correct with test set and tree size {treeSize}: {sum(test_accuracies)/len(test_accuracies):.2%}\")\n",
    "    print(f\"{time()-start:.2f} seconds elapsed\")\n",
    "print(f\"{time()-hard_start:.2f} seconds to run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "import glob\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = \"./data/data/data\"\n",
    "\n",
    "def load():\n",
    "    file_list = glob.glob(IMAGE_DIR + \"/*.jpg\")\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for fname in file_list:\n",
    "        with Image.open(fname) as img:\n",
    "            np_img = np.array(img).flatten()\n",
    "        label = int(os.path.split(fname)[-1].split('.')[0].split('_')[3])-1\n",
    "\n",
    "        X.append(np_img)\n",
    "        tempy = np.zeros(15)\n",
    "        tempy[label] = 1\n",
    "        Y.append(tempy)\n",
    "    X, Y = np.array(X), np.array(Y)\n",
    "    return(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data\n",
    "X, Y = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WL_loss(H, Y, classifier):\n",
    "    true_y = np.array(Y)\n",
    "    y_size = true_y.shape[0]\n",
    "    running = []\n",
    "    print(true_y[classifier])\n",
    "    for wl in H:\n",
    "        val = 1 - (true_y[classifier].reshape(1, true_y[classifier].shape[0]) @ np.array(wl.y_pred))/len(wl.y_pred)\n",
    "        running.append(max(0,val))\n",
    "    return max(running)\n",
    "#     return (sum([max(0, 1 - (true_y[classifier].reshape(1, true_y[classifier].shape[0]) @ np.array(wl.y_pred))/len(wl.y_pred)) for wl in H])/len(H))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(weights, best):\n",
    "    def f(x):\n",
    "        return 1/2*(1/(1-best.error_rate)) * x if x in best.miss_data else 1/2*(1/best.error_rate) * x\n",
    "    return np.array(map(f,weights)).tolist()\n",
    "\n",
    "def run(Weak_Learners, data, eval_set, H, weights):\n",
    "    for wl in Weak_Learners:\n",
    "        wl.fit(data, eval_set)\n",
    "        wl.miss_classify(data, eval_set)\n",
    "        wl.calc_error_rate(weights)\n",
    "    \n",
    "    best = Weak_Learners[0]\n",
    "    for wl in Weak_Learners:\n",
    "        if wl.error_rate < best.error_rate:\n",
    "            best = wl\n",
    "    \n",
    "    best.calc_voting_power()\n",
    "    H.append(best)\n",
    "    \n",
    "    weights = update_weights(weights, best)\n",
    "    \n",
    "    accuracy = H_accuracy(H, data, eval_set)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "86.587%, 86.587%\n",
      "Average: 86.587%\n",
      "Class 6\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.200%, 87.200%, 87.200%, 87.200%, 87.200%, 87.200%, 87.200%, 87.200%, 87.200%, 87.200%\n",
      "Average: 87.200%\n",
      "        test:\n",
      "            86.160%, 86.160%, 86.160%, 86.160%, 86.160%, 86.160%, 86.160%, 86.160%, 86.160%, 86.160%\n",
      "Average: 86.160%\n",
      "Class 7\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.560%, 86.560%, 86.560%, 86.560%, 86.560%, 86.560%, 86.560%, 86.560%, 86.560%, 86.560%\n",
      "Average: 86.560%\n",
      "        test:\n",
      "            86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%\n",
      "Average: 86.267%\n",
      "Class 8\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.120%, 87.120%, 87.120%, 87.120%, 87.120%, 87.120%, 87.120%, 87.120%, 87.120%, 87.120%\n",
      "Average: 87.120%\n",
      "        test:\n",
      "            85.627%, 85.627%, 85.627%, 85.627%, 85.627%, 85.627%, 85.627%, 85.627%, 85.627%, 85.627%\n",
      "Average: 85.627%\n",
      "Class 9\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.827%, 86.827%, 86.827%, 86.827%, 86.827%, 86.827%, 86.827%, 86.827%, 86.827%, 86.827%\n",
      "Average: 86.827%\n",
      "        test:\n",
      "            86.640%, 86.640%, 86.640%, 86.640%, 86.640%, 86.640%, 86.640%, 86.640%, 86.640%, 86.640%\n",
      "Average: 86.640%\n",
      "Class 10\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.480%, 86.480%, 86.480%, 86.480%, 86.480%, 86.480%, 86.480%, 86.480%, 86.480%, 86.480%\n",
      "Average: 86.480%\n",
      "        test:\n",
      "            86.853%, 86.853%, 86.853%, 86.853%, 86.853%, 86.853%, 86.853%, 86.853%, 86.853%, 86.853%\n",
      "Average: 86.853%\n",
      "Class 11\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%\n",
      "Average: 86.667%\n",
      "        test:\n",
      "            86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%\n",
      "Average: 86.667%\n",
      "Class 12\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.320%, 86.320%, 86.320%, 86.320%, 86.320%, 86.320%, 86.320%, 86.320%, 86.320%, 86.320%\n",
      "Average: 86.320%\n",
      "        test:\n",
      "            87.013%, 87.013%, 87.013%, 87.013%, 87.013%, 87.013%, 87.013%, 87.013%, 87.013%, 87.013%\n",
      "Average: 87.013%\n",
      "Class 13\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.827%, 86.827%, 86.827%, 86.827%, 86.827%, 86.827%, 86.827%, 86.827%, 86.827%, 86.827%\n",
      "Average: 86.827%\n",
      "        test:\n",
      "            86.587%, 86.587%, 86.587%, 86.587%, 86.587%, 86.587%, 86.587%, 86.587%, 86.587%, 86.587%\n",
      "Average: 86.587%\n",
      "Class 14\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.227%, 87.227%, 87.227%, 87.227%, 87.227%, 87.227%, 87.227%, 87.227%, 87.227%, 87.227%\n",
      "Average: 87.227%\n",
      "        test:\n",
      "            87.147%, 87.147%, 87.147%, 87.147%, 87.147%, 87.147%, 87.147%, 87.147%, 87.147%, 87.147%\n",
      "Average: 87.147%\n",
      "Class 0\n",
      "    accuracies:\n",
      "        train:\n",
      "            88.578%, 88.578%, 88.578%, 88.578%, 88.578%, 88.578%, 88.578%, 88.578%, 88.578%, 88.578%\n",
      "Average: 88.578%\n",
      "        test:\n",
      "            87.567%, 87.567%, 87.567%, 87.567%, 87.567%, 87.567%, 87.567%, 87.567%, 87.567%, 87.567%\n",
      "Average: 87.567%\n",
      "Class 1\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.378%, 86.378%, 86.378%, 86.378%, 86.378%, 86.378%, 86.378%, 86.378%, 86.378%, 86.378%\n",
      "Average: 86.378%\n",
      "        test:\n",
      "            87.100%, 87.100%, 87.100%, 87.100%, 87.100%, 87.100%, 87.100%, 87.100%, 87.100%, 87.100%\n",
      "Average: 87.100%\n",
      "Class 2\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.356%, 86.356%, 86.356%, 86.356%, 86.356%, 86.356%, 86.356%, 86.356%, 86.356%, 86.356%\n",
      "Average: 86.356%\n",
      "        test:\n",
      "            87.133%, 87.133%, 87.133%, 87.133%, 87.133%, 87.133%, 87.133%, 87.133%, 87.133%, 87.133%\n",
      "Average: 87.133%\n",
      "Class 3\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.778%, 86.778%, 86.778%, 86.778%, 86.778%, 86.778%, 86.778%, 86.778%, 86.778%, 86.778%\n",
      "Average: 86.778%\n",
      "        test:\n",
      "            86.500%, 86.500%, 86.500%, 86.500%, 86.500%, 86.500%, 86.500%, 86.500%, 86.500%, 86.500%\n",
      "Average: 86.500%\n",
      "Class 4\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.533%, 87.533%, 87.533%, 87.533%, 87.533%, 87.533%, 87.533%, 87.533%, 87.533%, 87.533%\n",
      "Average: 87.533%\n",
      "        test:\n",
      "            86.300%, 86.300%, 86.300%, 86.300%, 86.300%, 86.300%, 86.300%, 86.300%, 86.300%, 86.300%\n",
      "Average: 86.300%\n",
      "Class 5\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.444%, 86.444%, 86.444%, 86.444%, 86.444%, 86.444%, 86.444%, 86.444%, 86.444%, 86.444%\n",
      "Average: 86.444%\n",
      "        test:\n",
      "            87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%\n",
      "Average: 87.000%\n",
      "Class 6\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%\n",
      "Average: 87.000%\n",
      "        test:\n",
      "            86.233%, 86.233%, 86.233%, 86.233%, 86.233%, 86.233%, 86.233%, 86.233%, 86.233%, 86.233%\n",
      "Average: 86.233%\n",
      "Class 7\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.489%, 86.489%, 86.489%, 86.489%, 86.489%, 86.489%, 86.489%, 86.489%, 86.489%, 86.489%\n",
      "Average: 86.489%\n",
      "        test:\n",
      "            86.933%, 86.933%, 86.933%, 86.933%, 86.933%, 86.933%, 86.933%, 86.933%, 86.933%, 86.933%\n",
      "Average: 86.933%\n",
      "Class 8\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.111%, 87.111%, 87.111%, 87.111%, 87.111%, 87.111%, 87.111%, 87.111%, 87.111%, 87.111%\n",
      "Average: 87.111%\n",
      "        test:\n",
      "            85.300%, 85.300%, 85.300%, 85.300%, 85.300%, 85.300%, 85.300%, 85.300%, 85.300%, 85.300%\n",
      "Average: 85.300%\n",
      "Class 9\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%\n",
      "Average: 87.000%\n",
      "        test:\n",
      "            86.200%, 86.200%, 86.200%, 86.200%, 86.200%, 86.200%, 86.200%, 86.200%, 86.200%, 86.200%\n",
      "Average: 86.200%\n",
      "Class 10\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.644%, 86.644%, 86.644%, 86.644%, 86.644%, 86.644%, 86.644%, 86.644%, 86.644%, 86.644%\n",
      "Average: 86.644%\n",
      "        test:\n",
      "            86.700%, 86.700%, 86.700%, 86.700%, 86.700%, 86.700%, 86.700%, 86.700%, 86.700%, 86.700%\n",
      "Average: 86.700%\n",
      "Class 11\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%\n",
      "Average: 86.667%\n",
      "        test:\n",
      "            86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%\n",
      "Average: 86.667%\n",
      "Class 12\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.333%, 86.333%, 86.333%, 86.333%, 86.333%, 86.333%, 86.333%, 86.333%, 86.333%, 86.333%\n",
      "Average: 86.333%\n",
      "        test:\n",
      "            87.167%, 87.167%, 87.167%, 87.167%, 87.167%, 87.167%, 87.167%, 87.167%, 87.167%, 87.167%\n",
      "Average: 87.167%\n",
      "Class 13\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.956%, 86.956%, 86.956%, 86.956%, 86.956%, 86.956%, 86.956%, 86.956%, 86.956%, 86.956%\n",
      "Average: 86.956%\n",
      "        test:\n",
      "            85.933%, 85.933%, 85.933%, 85.933%, 85.933%, 85.933%, 85.933%, 85.933%, 85.933%, 85.933%\n",
      "Average: 85.933%\n",
      "Class 14\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.467%, 86.467%, 86.467%, 86.467%, 86.467%, 86.467%, 86.467%, 86.467%, 86.467%, 86.467%\n",
      "Average: 86.467%\n",
      "        test:\n",
      "            86.967%, 86.967%, 86.967%, 86.967%, 86.967%, 86.967%, 86.967%, 86.967%, 86.967%, 86.967%\n",
      "Average: 86.967%\n",
      "Class 0\n",
      "    accuracies:\n",
      "        train:\n",
      "            88.552%, 88.552%, 88.552%, 88.552%, 88.552%, 88.552%, 88.552%, 88.552%, 88.552%, 88.552%\n",
      "Average: 88.552%\n",
      "        test:\n",
      "            86.222%, 86.222%, 86.222%, 86.222%, 86.222%, 86.222%, 86.222%, 86.222%, 86.222%, 86.222%\n",
      "Average: 86.222%\n",
      "Class 1\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.438%, 86.438%, 86.438%, 86.438%, 86.438%, 86.438%, 86.438%, 86.438%, 86.438%, 86.438%\n",
      "Average: 86.438%\n",
      "        test:\n",
      "            87.200%, 87.200%, 87.200%, 87.200%, 87.200%, 87.200%, 87.200%, 87.200%, 87.200%, 87.200%\n",
      "Average: 87.200%\n",
      "Class 2\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.705%, 86.705%, 86.705%, 86.705%, 86.705%, 86.705%, 86.705%, 86.705%, 86.705%, 86.705%\n",
      "Average: 86.705%\n",
      "        test:\n",
      "            86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%\n",
      "Average: 86.578%\n",
      "Class 3\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.610%, 86.610%, 86.610%, 86.610%, 86.610%, 86.610%, 86.610%, 86.610%, 86.610%, 86.610%\n",
      "Average: 86.610%\n",
      "        test:\n",
      "            87.289%, 87.289%, 87.289%, 87.289%, 87.289%, 87.289%, 87.289%, 87.289%, 87.289%, 87.289%\n",
      "Average: 87.289%\n",
      "Class 4\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.257%, 87.257%, 87.257%, 87.257%, 87.257%, 87.257%, 87.257%, 87.257%, 87.257%, 87.257%\n",
      "Average: 87.257%\n",
      "        test:\n",
      "            85.689%, 85.689%, 85.689%, 85.689%, 85.689%, 85.689%, 85.689%, 85.689%, 85.689%, 85.689%\n",
      "Average: 85.689%\n",
      "Class 5\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.362%, 86.362%, 86.362%, 86.362%, 86.362%, 86.362%, 86.362%, 86.362%, 86.362%, 86.362%\n",
      "Average: 86.362%\n",
      "        test:\n",
      "            87.378%, 87.378%, 87.378%, 87.378%, 87.378%, 87.378%, 87.378%, 87.378%, 87.378%, 87.378%\n",
      "Average: 87.378%\n",
      "Class 6\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.971%, 86.971%, 86.971%, 86.971%, 86.971%, 86.971%, 86.971%, 86.971%, 86.971%, 86.971%\n",
      "Average: 86.971%\n",
      "        test:\n",
      "            86.044%, 86.044%, 86.044%, 86.044%, 86.044%, 86.044%, 86.044%, 86.044%, 86.044%, 86.044%\n",
      "Average: 86.044%\n",
      "Class 7\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%\n",
      "Average: 86.267%\n",
      "        test:\n",
      "            87.600%, 87.600%, 87.600%, 87.600%, 87.600%, 87.600%, 87.600%, 87.600%, 87.600%, 87.600%\n",
      "Average: 87.600%\n",
      "Class 8\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.143%, 87.143%, 87.143%, 87.143%, 87.143%, 87.143%, 87.143%, 87.143%, 87.143%, 87.143%\n",
      "Average: 87.143%\n",
      "        test:\n",
      "            85.556%, 85.556%, 85.556%, 85.556%, 85.556%, 85.556%, 85.556%, 85.556%, 85.556%, 85.556%\n",
      "Average: 85.556%\n",
      "Class 9\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.895%, 86.895%, 86.895%, 86.895%, 86.895%, 86.895%, 86.895%, 86.895%, 86.895%, 86.895%\n",
      "Average: 86.895%\n",
      "        test:\n",
      "            86.133%, 86.133%, 86.133%, 86.133%, 86.133%, 86.133%, 86.133%, 86.133%, 86.133%, 86.133%\n",
      "Average: 86.133%\n",
      "Class 10\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.705%, 86.705%, 86.705%, 86.705%, 86.705%, 86.705%, 86.705%, 86.705%, 86.705%, 86.705%\n",
      "Average: 86.705%\n",
      "        test:\n",
      "            86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%\n",
      "Average: 86.578%\n",
      "Class 11\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.495%, 86.495%, 86.495%, 86.495%, 86.495%, 86.495%, 86.495%, 86.495%, 86.495%, 86.495%\n",
      "Average: 86.495%\n",
      "        test:\n",
      "            87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%\n",
      "Average: 87.067%\n",
      "Class 12\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.514%, 86.514%, 86.514%, 86.514%, 86.514%, 86.514%, 86.514%, 86.514%, 86.514%, 86.514%\n",
      "Average: 86.514%\n",
      "        test:\n",
      "            87.022%, 87.022%, 87.022%, 87.022%, 87.022%, 87.022%, 87.022%, 87.022%, 87.022%, 87.022%\n",
      "Average: 87.022%\n",
      "Class 13\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.048%, 87.048%, 87.048%, 87.048%, 87.048%, 87.048%, 87.048%, 87.048%, 87.048%, 87.048%\n",
      "Average: 87.048%\n",
      "        test:\n",
      "            85.822%, 85.822%, 85.822%, 85.822%, 85.822%, 85.822%, 85.822%, 85.822%, 85.822%, 85.822%\n",
      "Average: 85.822%\n",
      "Class 14\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.495%, 86.495%, 86.495%, 86.495%, 86.495%, 86.495%, 86.495%, 86.495%, 86.495%, 86.495%\n",
      "Average: 86.495%\n",
      "        test:\n",
      "            87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%\n",
      "Average: 87.067%\n",
      "Class 0\n",
      "    accuracies:\n",
      "        train:\n",
      "            88.683%, 88.683%, 88.683%, 88.683%, 88.683%, 88.683%, 88.683%, 88.683%, 88.683%, 88.683%\n",
      "Average: 88.683%\n",
      "        test:\n",
      "            87.733%, 87.733%, 87.733%, 87.733%, 87.733%, 87.733%, 87.733%, 87.733%, 87.733%, 87.733%\n",
      "Average: 87.733%\n",
      "Class 1\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.567%, 86.567%, 86.567%, 86.567%, 86.567%, 86.567%, 86.567%, 86.567%, 86.567%, 86.567%\n",
      "Average: 86.567%\n",
      "        test:\n",
      "            87.133%, 87.133%, 87.133%, 87.133%, 87.133%, 87.133%, 87.133%, 87.133%, 87.133%, 87.133%\n",
      "Average: 87.133%\n",
      "Class 2\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.883%, 86.883%, 86.883%, 86.883%, 86.883%, 86.883%, 86.883%, 86.883%, 86.883%, 86.883%\n",
      "Average: 86.883%\n",
      "        test:\n",
      "            85.933%, 85.933%, 85.933%, 85.933%, 85.933%, 85.933%, 85.933%, 85.933%, 85.933%, 85.933%\n",
      "Average: 85.933%\n",
      "Class 3\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.483%, 86.483%, 86.483%, 86.483%, 86.483%, 86.483%, 86.483%, 86.483%, 86.483%, 86.483%\n",
      "Average: 86.483%\n",
      "        test:\n",
      "            88.133%, 88.133%, 88.133%, 88.133%, 88.133%, 88.133%, 88.133%, 88.133%, 88.133%, 88.133%\n",
      "Average: 88.133%\n",
      "Class 4\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.533%, 87.533%, 87.533%, 87.533%, 87.533%, 87.533%, 87.533%, 87.533%, 87.533%, 87.533%\n",
      "Average: 87.533%\n",
      "        test:\n",
      "            85.067%, 85.067%, 85.067%, 85.067%, 85.067%, 85.067%, 85.067%, 85.067%, 85.067%, 85.067%\n",
      "Average: 85.067%\n",
      "Class 5\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.483%, 86.483%, 86.483%, 86.483%, 86.483%, 86.483%, 86.483%, 86.483%, 86.483%, 86.483%\n",
      "Average: 86.483%\n",
      "        test:\n",
      "            87.400%, 87.400%, 87.400%, 87.400%, 87.400%, 87.400%, 87.400%, 87.400%, 87.400%, 87.400%\n",
      "Average: 87.400%\n",
      "Class 6\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.967%, 86.967%, 86.967%, 86.967%, 86.967%, 86.967%, 86.967%, 86.967%, 86.967%, 86.967%\n",
      "Average: 86.967%\n",
      "        test:\n",
      "            85.533%, 85.533%, 85.533%, 85.533%, 85.533%, 85.533%, 85.533%, 85.533%, 85.533%, 85.533%\n",
      "Average: 85.533%\n",
      "Class 7\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%\n",
      "Average: 86.267%\n",
      "        test:\n",
      "            88.267%, 88.267%, 88.267%, 88.267%, 88.267%, 88.267%, 88.267%, 88.267%, 88.267%, 88.267%\n",
      "Average: 88.267%\n",
      "Class 8\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.817%, 86.817%, 86.817%, 86.817%, 86.817%, 86.817%, 86.817%, 86.817%, 86.817%, 86.817%\n",
      "Average: 86.817%\n",
      "        test:\n",
      "            86.200%, 86.200%, 86.200%, 86.200%, 86.200%, 86.200%, 86.200%, 86.200%, 86.200%, 86.200%\n",
      "Average: 86.200%\n",
      "Class 9\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.833%, 86.833%, 86.833%, 86.833%, 86.833%, 86.833%, 86.833%, 86.833%, 86.833%, 86.833%\n",
      "Average: 86.833%\n",
      "        test:\n",
      "            86.000%, 86.000%, 86.000%, 86.000%, 86.000%, 86.000%, 86.000%, 86.000%, 86.000%, 86.000%\n",
      "Average: 86.000%\n",
      "Class 10\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.867%, 86.867%, 86.867%, 86.867%, 86.867%, 86.867%, 86.867%, 86.867%, 86.867%, 86.867%\n",
      "Average: 86.867%\n",
      "        test:\n",
      "            85.867%, 85.867%, 85.867%, 85.867%, 85.867%, 85.867%, 85.867%, 85.867%, 85.867%, 85.867%\n",
      "Average: 85.867%\n",
      "Class 11\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.633%, 86.633%, 86.633%, 86.633%, 86.633%, 86.633%, 86.633%, 86.633%, 86.633%, 86.633%\n",
      "Average: 86.633%\n",
      "        test:\n",
      "            86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%\n",
      "Average: 86.800%\n",
      "Class 12\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.417%, 86.417%, 86.417%, 86.417%, 86.417%, 86.417%, 86.417%, 86.417%, 86.417%, 86.417%\n",
      "Average: 86.417%\n",
      "        test:\n",
      "            87.667%, 87.667%, 87.667%, 87.667%, 87.667%, 87.667%, 87.667%, 87.667%, 87.667%, 87.667%\n",
      "Average: 87.667%\n",
      "Class 13\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.817%, 86.817%, 86.817%, 86.817%, 86.817%, 86.817%, 86.817%, 86.817%, 86.817%, 86.817%\n",
      "Average: 86.817%\n",
      "        test:\n",
      "            86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%\n",
      "Average: 86.267%\n",
      "Class 14\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.517%, 86.517%, 86.517%, 86.517%, 86.517%, 86.517%, 86.517%, 86.517%, 86.517%, 86.517%\n",
      "Average: 86.517%\n",
      "        test:\n",
      "            87.267%, 87.267%, 87.267%, 87.267%, 87.267%, 87.267%, 87.267%, 87.267%, 87.267%, 87.267%\n",
      "Average: 87.267%\n",
      "Class 0\n",
      "    accuracies:\n",
      "        train:\n",
      "            88.296%, 88.296%, 88.296%, 88.296%, 88.296%, 88.296%, 88.296%, 88.296%, 88.296%, 88.296%\n",
      "Average: 88.296%\n",
      "        test:\n",
      "            88.400%, 88.400%, 88.400%, 88.400%, 88.400%, 88.400%, 88.400%, 88.400%, 88.400%, 88.400%\n",
      "Average: 88.400%\n",
      "Class 1\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.533%, 86.533%, 86.533%, 86.533%, 86.533%, 86.533%, 86.533%, 86.533%, 86.533%, 86.533%\n",
      "Average: 86.533%\n",
      "        test:\n",
      "            88.000%, 88.000%, 88.000%, 88.000%, 88.000%, 88.000%, 88.000%, 88.000%, 88.000%, 88.000%\n",
      "Average: 88.000%\n",
      "Class 2\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%\n",
      "Average: 86.667%\n",
      "        test:\n",
      "            86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%\n",
      "Average: 86.667%\n",
      "Class 3\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%\n",
      "Average: 86.652%\n",
      "        test:\n",
      "            87.867%, 87.867%, 87.867%, 87.867%, 87.867%, 87.867%, 87.867%, 87.867%, 87.867%, 87.867%\n",
      "Average: 87.867%\n",
      "Class 4\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.230%, 87.230%, 87.230%, 87.230%, 87.230%, 87.230%, 87.230%, 87.230%, 87.230%, 87.230%\n",
      "Average: 87.230%\n",
      "        test:\n",
      "            85.333%, 85.333%, 85.333%, 85.333%, 85.333%, 85.333%, 85.333%, 85.333%, 85.333%, 85.333%\n",
      "Average: 85.333%\n",
      "Class 5\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%\n",
      "Average: 86.578%\n",
      "        test:\n",
      "            87.467%, 87.467%, 87.467%, 87.467%, 87.467%, 87.467%, 87.467%, 87.467%, 87.467%, 87.467%\n",
      "Average: 87.467%\n",
      "Class 6\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%\n",
      "Average: 87.067%\n",
      "        test:\n",
      "            83.333%, 83.333%, 83.333%, 83.333%, 83.333%, 83.333%, 83.333%, 83.333%, 83.333%, 83.333%\n",
      "Average: 83.333%\n",
      "Class 7\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.400%, 86.400%, 86.400%, 86.400%, 86.400%, 86.400%, 86.400%, 86.400%, 86.400%, 86.400%\n",
      "Average: 86.400%\n",
      "        test:\n",
      "            89.067%, 89.067%, 89.067%, 89.067%, 89.067%, 89.067%, 89.067%, 89.067%, 89.067%, 89.067%\n",
      "Average: 89.067%\n",
      "Class 8\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%\n",
      "Average: 86.652%\n",
      "        test:\n",
      "            86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%\n",
      "Average: 86.800%\n",
      "Class 9\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.874%, 86.874%, 86.874%, 86.874%, 86.874%, 86.874%, 86.874%, 86.874%, 86.874%, 86.874%\n",
      "Average: 86.874%\n",
      "        test:\n",
      "            84.800%, 84.800%, 84.800%, 84.800%, 84.800%, 84.800%, 84.800%, 84.800%, 84.800%, 84.800%\n",
      "Average: 84.800%\n",
      "Class 10\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.711%, 86.711%, 86.711%, 86.711%, 86.711%, 86.711%, 86.711%, 86.711%, 86.711%, 86.711%\n",
      "Average: 86.711%\n",
      "        test:\n",
      "            86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%\n",
      "Average: 86.267%\n",
      "Class 11\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.681%, 86.681%, 86.681%, 86.681%, 86.681%, 86.681%, 86.681%, 86.681%, 86.681%, 86.681%\n",
      "Average: 86.681%\n",
      "        test:\n",
      "            86.533%, 86.533%, 86.533%, 86.533%, 86.533%, 86.533%, 86.533%, 86.533%, 86.533%, 86.533%\n",
      "Average: 86.533%\n",
      "Class 12\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%\n",
      "Average: 86.652%\n",
      "        test:\n",
      "            86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%\n",
      "Average: 86.800%\n",
      "Class 13\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.756%, 86.756%, 86.756%, 86.756%, 86.756%, 86.756%, 86.756%, 86.756%, 86.756%, 86.756%\n",
      "Average: 86.756%\n",
      "        test:\n",
      "            86.400%, 86.400%, 86.400%, 86.400%, 86.400%, 86.400%, 86.400%, 86.400%, 86.400%, 86.400%\n",
      "Average: 86.400%\n",
      "Class 14\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.415%, 86.415%, 86.415%, 86.415%, 86.415%, 86.415%, 86.415%, 86.415%, 86.415%, 86.415%\n",
      "Average: 86.415%\n",
      "        test:\n",
      "            88.933%, 88.933%, 88.933%, 88.933%, 88.933%, 88.933%, 88.933%, 88.933%, 88.933%, 88.933%\n",
      "Average: 88.933%\n"
     ]
    }
   ],
>>>>>>> 1a1584ae47198bcc19eb9cc31406c45a2e14792a
   "source": [
    "from time import time\n",
    "\n",
    "trainSizes = [x/10 for x in range(1,10)]\n",
    "hard_start = time()\n",
    "\n",
    "def print_dict(dictionary, sep=''):\n",
    "    for key in dictionary.keys():\n",
    "        new_sep = sep+'    '\n",
    "        if type(key) is int:\n",
    "            print(f\"Class {key}\")\n",
    "        else:\n",
    "            print(f\"{sep}{key}:\")\n",
    "        if type(dictionary[key]) is dict:\n",
    "            print_dict(dictionary[key], sep=new_sep)\n",
    "        elif key == \"losses\":\n",
    "            val_str = \"\"\n",
    "            for i in range(len(dictionary[key])-1):\n",
    "                val_str += f\"{dictionary[key][i]:.2f}, \"\n",
    "            val_str += f\"{dictionary[key][-1]:.2f}\"\n",
    "            print(f\"{new_sep}{val_str}\")\n",
    "            print(f\"Average: {sum(dictionary[key])/len(dictionary[key]):.2f}\")\n",
    "        elif type(dictionary[key]) is list:\n",
    "            val_str = \"\"\n",
    "            for i in range(len(dictionary[key])-1):\n",
    "                val_str += f\"{dictionary[key][i]:.3%}, \"\n",
    "            val_str += f\"{dictionary[key][-1]:.3%}\"\n",
    "            print(f\"{new_sep}{val_str}\")\n",
    "            print(f\"Average: {sum(dictionary[key])/len(dictionary[key]):.3%}\")\n",
    "        else:\n",
    "            print(f\"{new_sep}{dictionary[key]}\")\n",
    "\n",
    "def thread_loss(H, Y, classifier):\n",
    "    true_y = np.array(Y)\n",
    "    return (sum([max(0, 1 - (true_y.reshape(1, true_y.shape[0]) @ np.array(wl.y_pred))/len(wl.y_pred)) for wl in H])/len(H))[0]\n",
    "            \n",
    "def runner(pnum, ptracker, rcount, Xtrain, Ytrain, Xtest, Ytest, classifier):\n",
    "    H = []\n",
    "    Weak_Learners = []\n",
    "    for i in range(10):\n",
    "        model = ShallowTree()\n",
    "        Weak_Learners.append(WeakLearner(model, classifier))\n",
    "    weights = np.array([1/len(Xtrain) for _ in range(len(Xtrain))])\n",
    "    for r in range(10):\n",
    "        ptracker[rcount][pnum][\"accuracies\"][\"train\"].append(run(Weak_Learners, Xtrain, Ytrain, H, weights))\n",
    "        ptracker[rcount][pnum][\"losses\"].append(thread_loss(H, Ytrain, classifier))\n",
    "        ptracker[rcount][pnum][\"accuracies\"][\"test\"].append(H_accuracy(H, Xtest, Ytest))\n",
    "\n",
    "def f(pnum, ptracker, rcount, split, X, Y):\n",
    "    for i in range(pnum):\n",
    "        ptracker[rcount][i] = {}\n",
    "        ptracker[rcount][i][\"accuracies\"] = {\"train\": [], \"test\": []}\n",
    "        ptracker[rcount][i][\"losses\"] = []\n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, train_size=split, random_state = 2021)\n",
    "    Ytrain_classes = [classify(Ytrain, i) for i in range(15)]\n",
    "    Ytest_classes = [classify(Ytest, i) for i in range(15)]\n",
    "    jobs = []\n",
    "    for i in range(15):\n",
    "        proc = threading.Thread(target=runner, args=(i, ptracker, rcount, Xtrain, Ytrain_classes[i], Xtest, Ytest_classes[i], i), name=f\"Thread {i}\")\n",
    "        jobs.append(proc)\n",
    "        proc.start()\n",
    "    \n",
    "    for count,p in enumerate(jobs):\n",
    "        p.join()\n",
    "\n",
    "ptrackers = [{} for _ in trainSizes]\n",
    "for i,ratio in enumerate(trainSizes):\n",
    "    f(15, ptrackers, i, ratio, X, Y)\n",
    "for i in range(len(ptrackers)):\n",
    "    print(f\"Ratio: {trainSizes[i]}\")\n",
    "    print_dict(ptrackers[i])\n",
    "# ratio_threads = []\n",
    "# for i,ratio in enumerate(trainSizes):\n",
    "#     print(f\"Running ratio: {ratio:.0%}\")\n",
    "#     proc = threading.Thread(target=f, args=(15, ptrackers, i, ratio, X, Y))\n",
    "#     ratio_threads.append(proc)\n",
    "#     proc.start()\n",
    "\n",
    "# for i, proc in enumerate(ratio_threads):\n",
    "#     proc.join()\n",
    "#     print_dict(ptrackers[i])\n",
    "print(f\"Took {time()-hard_start} seconds to run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1 -1 ... -1 -1 -1]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to numpy.ndarray.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d348bfe4a8f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[0mtrain_local_accuracies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWeak_Learners\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtrain_classes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Loss on run {r}: {WL_loss(H, Ytrain_classes, i):.3f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m             \u001b[0mtest_local_accuracies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtest_classes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported format string passed to numpy.ndarray.__format__"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Here we test the performace of our model with different amounts of training data \n",
    "\"\"\"\n",
    "from time import time\n",
    "\n",
    "trainSizes = [x / 10 for x in range(1, 10, 1)] # Create a list of [0.5, ..., 0.9] If x < 0.5 we get an out of bounds error on the weights\n",
    "\n",
    "hard_start = time()\n",
    "\n",
    "for trainRatio in trainSizes:\n",
    "    start = time()\n",
    "    \n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, train_size=trainRatio, random_state=2021)\n",
    "    Ytrain_classes = []\n",
    "    Ytest_classes = []\n",
    "    for i in range(Ytrain.shape[1]):\n",
    "        Ytrain_i = classify(Ytrain, i)\n",
    "        Ytrain_classes.append(Ytrain_i)\n",
    "        Ytest_i = classify(Ytest, i)\n",
    "        Ytest_classes.append(Ytest_i)\n",
    "    \n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "    for i in range(Ytrain.shape[1]):\n",
    "        H = []\n",
    "        Weak_Learners = []\n",
    "        for _ in range(10):\n",
    "            model = ShallowTree()\n",
    "            model.fit(Xtrain, Ytrain_classes[0])\n",
    "            Weak_Learners.append(WeakLearner(model, 0))\n",
    "\n",
    "        weights = np.array([1/len(Xtrain) for _ in range(len(Xtrain))])\n",
    "        train_local_accuracies = []\n",
    "        test_local_accuracies = []\n",
    "        for r in range(10):\n",
    "            train_local_accuracies.append(run(Weak_Learners, Xtrain, Ytrain_classes[i], H, weights))\n",
    "            print(f\"Loss on run {r}: {WL_loss(H, Ytrain_classes, i):.3f}\")\n",
    "            test_local_accuracies.append(H_accuracy(H, Xtest, Ytest_classes[i]))\n",
    "\n",
    "        train_accuracies.append(sum(train_local_accuracies) / len(train_local_accuracies))\n",
    "        test_accuracies.append(sum(test_local_accuracies)/len(test_local_accuracies))\n",
    "        \n",
    "\n",
    "    print(f\"Ratio: {trainRatio:.2%}\\n\\t Train Accuracy: {sum(train_accuracies)/len(train_accuracies):.2%}\")\n",
    "    print(f\"Ratio: {trainRatio:.2%}\\n\\t Test Accuracy: {sum(test_accuracies)/len(test_accuracies):.2%}\")\n",
    "    print(f\"{time()-start:.2f} seconds elapsed\")\n",
    "    \n",
    "print(f\"{time()-hard_start:.2f} seconds to run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13500, 15)\n",
      "(1500, 15)\n"
     ]
    }
   ],
   "source": [
    "print(Ytrain.shape)\n",
    "print(Ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent correct with training set and tree size 2: 82.10%\n",
      "Percent correct with test set and tree size 2: 82.49%\n",
      "685.31 seconds elapsed\n",
      "Percent correct with training set and tree size 3: 81.15%\n",
      "Percent correct with test set and tree size 3: 81.34%\n",
      "770.76 seconds elapsed\n",
      "Percent correct with training set and tree size 4: 80.59%\n",
      "Percent correct with test set and tree size 4: 80.99%\n",
      "848.00 seconds elapsed\n",
      "Percent correct with training set and tree size 5: 80.21%\n",
      "Percent correct with test set and tree size 5: 80.79%\n",
      "872.08 seconds elapsed\n",
      "Percent correct with training set and tree size 6: 79.90%\n",
      "Percent correct with test set and tree size 6: 80.59%\n",
      "962.80 seconds elapsed\n",
      "Percent correct with training set and tree size 7: 79.61%\n",
      "Percent correct with test set and tree size 7: 80.38%\n",
      "1051.88 seconds elapsed\n",
      "Percent correct with training set and tree size 8: 79.32%\n",
      "Percent correct with test set and tree size 8: 80.17%\n",
      "1139.44 seconds elapsed\n",
      "Percent correct with training set and tree size 9: 79.07%\n",
      "Percent correct with test set and tree size 9: 79.97%\n",
      "1230.19 seconds elapsed\n",
      "7560.57 seconds to run\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Now we vary the size of the trees\n",
    "We use 80% train, 20% test (The standard)\n",
    "\"\"\"\n",
    "hard_start = time()\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, train_size=0.8, random_state=2021)\n",
    "Ytrain_classes = []\n",
    "Ytest_classes = []\n",
    "\n",
    "\n",
    "for treeSize in range(2, 10):\n",
    "    start = time()\n",
    "    for i in range(Ytrain.shape[1]):\n",
    "        Ytrain_i = classify(Ytrain, i)\n",
    "        Ytrain_classes.append(Ytrain_i)\n",
    "        Ytest_i = classify(Ytest, i)\n",
    "        Ytest_classes.append(Ytest_i)\n",
    "\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "    for i in range(Ytrain.shape[1]):\n",
    "        H_train = []\n",
    "        H_test =[]\n",
    "        Weak_Learners = []\n",
    "        for _ in range(10):\n",
    "            model = ShallowTree(treeSize)\n",
    "            model.fit(Xtrain, Ytrain_classes[0])\n",
    "            Weak_Learners.append(WeakLearner(model, 0))\n",
    "\n",
    "        weights = np.array([1/len(Xtrain) for _ in range(len(Xtrain))])\n",
    "        local_accuracies = []\n",
    "        \n",
    "        for r in range(10):\n",
    "            train_local_accuracies.append(run(Weak_Learners, Xtrain, Ytrain_classes[i], H_train, weights))\n",
    "            test_local_accuracies.append(run(Weak_Learners, Xtest, Ytest_classes[i], H_test, weights))\n",
    "\n",
    "        train_accuracies.append(sum(train_local_accuracies) / len(train_local_accuracies))\n",
    "        test_accuracies.append(sum(test_local_accuracies)/len(test_local_accuracies))\n",
    "\n",
    "    print(f\"Percent correct with training set and tree size {treeSize}: {sum(train_accuracies)/len(train_accuracies):.2%}\")\n",
    "    print(f\"Percent correct with test set and tree size {treeSize}: {sum(test_accuracies)/len(test_accuracies):.2%}\")\n",
    "    print(f\"{time()-start:.2f} seconds elapsed\")\n",
    "print(f\"{time()-hard_start:.2f} seconds to run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
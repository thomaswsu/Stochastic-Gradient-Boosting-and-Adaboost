{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "import glob\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE_DIR = \"./data/data/data\"\n",
    "\n",
    "# def load():\n",
    "#     file_list = glob.glob(IMAGE_DIR + \"/*.jpg\")\n",
    "#     X = []\n",
    "#     Y = []\n",
    "\n",
    "#     for fname in file_list:\n",
    "#         with Image.open(fname) as img:\n",
    "#             np_img = np.array(img).flatten()\n",
    "#         label = int(os.path.split(fname)[-1].split('.')[0].split('_')[3])-1\n",
    "\n",
    "#         X.append(np_img)\n",
    "#         tempy = np.zeros(15)\n",
    "#         tempy[label] = 1\n",
    "#         Y.append(tempy)\n",
    "#     X, Y = np.array(X), np.array(Y)\n",
    "#     return(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data\n",
    "# X, Y = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1024)\n",
      "(60000, 1)\n"
     ]
    }
   ],
   "source": [
    "(Xtrain,Ytrain),(Xtest,Ytest) = cifar10.load_data()\n",
    "X = np.append(Xtrain, Xtest, 0)\n",
    "Y = np.append(Ytrain, Ytest, 0)\n",
    "X = rgb2gray(X)\n",
    "X = X.reshape(X.shape[0], np.prod(X.shape[1:]))\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def WL_loss(H, Y, classifier):\n",
    "#     true_y = np.array(Y)\n",
    "#     y_size = true_y.shape[0]\n",
    "#     running = []\n",
    "#     print(true_y[classifier])\n",
    "#     for wl in H:\n",
    "#         val = 1 - (true_y[classifier].reshape(1, true_y[classifier].shape[0]) @ np.array(wl.y_pred))/len(wl.y_pred)\n",
    "#         running.append(max(0,val))\n",
    "#     return max(running)\n",
    "# #     return (sum([max(0, 1 - (true_y[classifier].reshape(1, true_y[classifier].shape[0]) @ np.array(wl.y_pred))/len(wl.y_pred)) for wl in H])/len(H))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import threading, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def update_weights(weights, best):\n",
    "#     def f(x):\n",
    "#         return 1/2*(1/(1-best.error_rate)) * x if x in best.miss_data else 1/2*(1/best.error_rate) * x\n",
    "#     return np.array(map(f,weights)).tolist()\n",
    "\n",
    "# def run(Weak_Learners, data, eval_set, H, weights):\n",
    "#     for wl in Weak_Learners:\n",
    "#         wl.fit(data, eval_set)\n",
    "#         wl.miss_classify(data, eval_set)\n",
    "#         wl.calc_error_rate(weights)\n",
    "    \n",
    "#     best = Weak_Learners[0]\n",
    "#     for wl in Weak_Learners:\n",
    "#         if wl.error_rate < best.error_rate:\n",
    "#             best = wl\n",
    "    \n",
    "#     best.calc_voting_power()\n",
    "#     H.append(best)\n",
    "    \n",
    "#     weights = update_weights(weights, best)\n",
    "    \n",
    "#     accuracy = H_accuracy(H, data, eval_set)\n",
    "    \n",
    "#     return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import threading, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "86.587%, 86.587%\n",
      "Average: 86.587%\n",
      "Class 6\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.200%, 87.200%, 87.200%, 87.200%, 87.200%, 87.200%, 87.200%, 87.200%, 87.200%, 87.200%\n",
      "Average: 87.200%\n",
      "        test:\n",
      "            86.160%, 86.160%, 86.160%, 86.160%, 86.160%, 86.160%, 86.160%, 86.160%, 86.160%, 86.160%\n",
      "Average: 86.160%\n",
      "Class 7\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.560%, 86.560%, 86.560%, 86.560%, 86.560%, 86.560%, 86.560%, 86.560%, 86.560%, 86.560%\n",
      "Average: 86.560%\n",
      "        test:\n",
      "            86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%\n",
      "Average: 86.267%\n",
      "Class 8\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.120%, 87.120%, 87.120%, 87.120%, 87.120%, 87.120%, 87.120%, 87.120%, 87.120%, 87.120%\n",
      "Average: 87.120%\n",
      "        test:\n",
      "            85.627%, 85.627%, 85.627%, 85.627%, 85.627%, 85.627%, 85.627%, 85.627%, 85.627%, 85.627%\n",
      "Average: 85.627%\n",
      "Class 9\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.827%, 86.827%, 86.827%, 86.827%, 86.827%, 86.827%, 86.827%, 86.827%, 86.827%, 86.827%\n",
      "Average: 86.827%\n",
      "        test:\n",
      "            86.640%, 86.640%, 86.640%, 86.640%, 86.640%, 86.640%, 86.640%, 86.640%, 86.640%, 86.640%\n",
      "Average: 86.640%\n",
      "Class 10\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.480%, 86.480%, 86.480%, 86.480%, 86.480%, 86.480%, 86.480%, 86.480%, 86.480%, 86.480%\n",
      "Average: 86.480%\n",
      "        test:\n",
      "            86.853%, 86.853%, 86.853%, 86.853%, 86.853%, 86.853%, 86.853%, 86.853%, 86.853%, 86.853%\n",
      "Average: 86.853%\n",
      "Class 11\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%\n",
      "Average: 86.667%\n",
      "        test:\n",
      "            86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%\n",
      "Average: 86.667%\n",
      "Class 12\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.320%, 86.320%, 86.320%, 86.320%, 86.320%, 86.320%, 86.320%, 86.320%, 86.320%, 86.320%\n",
      "Average: 86.320%\n",
      "        test:\n",
      "            87.013%, 87.013%, 87.013%, 87.013%, 87.013%, 87.013%, 87.013%, 87.013%, 87.013%, 87.013%\n",
      "Average: 87.013%\n",
      "Class 13\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.827%, 86.827%, 86.827%, 86.827%, 86.827%, 86.827%, 86.827%, 86.827%, 86.827%, 86.827%\n",
      "Average: 86.827%\n",
      "        test:\n",
      "            86.587%, 86.587%, 86.587%, 86.587%, 86.587%, 86.587%, 86.587%, 86.587%, 86.587%, 86.587%\n",
      "Average: 86.587%\n",
      "Class 14\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.227%, 87.227%, 87.227%, 87.227%, 87.227%, 87.227%, 87.227%, 87.227%, 87.227%, 87.227%\n",
      "Average: 87.227%\n",
      "        test:\n",
      "            87.147%, 87.147%, 87.147%, 87.147%, 87.147%, 87.147%, 87.147%, 87.147%, 87.147%, 87.147%\n",
      "Average: 87.147%\n",
      "Class 0\n",
      "    accuracies:\n",
      "        train:\n",
      "            88.578%, 88.578%, 88.578%, 88.578%, 88.578%, 88.578%, 88.578%, 88.578%, 88.578%, 88.578%\n",
      "Average: 88.578%\n",
      "        test:\n",
      "            87.567%, 87.567%, 87.567%, 87.567%, 87.567%, 87.567%, 87.567%, 87.567%, 87.567%, 87.567%\n",
      "Average: 87.567%\n",
      "Class 1\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.378%, 86.378%, 86.378%, 86.378%, 86.378%, 86.378%, 86.378%, 86.378%, 86.378%, 86.378%\n",
      "Average: 86.378%\n",
      "        test:\n",
      "            87.100%, 87.100%, 87.100%, 87.100%, 87.100%, 87.100%, 87.100%, 87.100%, 87.100%, 87.100%\n",
      "Average: 87.100%\n",
      "Class 2\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.356%, 86.356%, 86.356%, 86.356%, 86.356%, 86.356%, 86.356%, 86.356%, 86.356%, 86.356%\n",
      "Average: 86.356%\n",
      "        test:\n",
      "            87.133%, 87.133%, 87.133%, 87.133%, 87.133%, 87.133%, 87.133%, 87.133%, 87.133%, 87.133%\n",
      "Average: 87.133%\n",
      "Class 3\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.778%, 86.778%, 86.778%, 86.778%, 86.778%, 86.778%, 86.778%, 86.778%, 86.778%, 86.778%\n",
      "Average: 86.778%\n",
      "        test:\n",
      "            86.500%, 86.500%, 86.500%, 86.500%, 86.500%, 86.500%, 86.500%, 86.500%, 86.500%, 86.500%\n",
      "Average: 86.500%\n",
      "Class 4\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.533%, 87.533%, 87.533%, 87.533%, 87.533%, 87.533%, 87.533%, 87.533%, 87.533%, 87.533%\n",
      "Average: 87.533%\n",
      "        test:\n",
      "            86.300%, 86.300%, 86.300%, 86.300%, 86.300%, 86.300%, 86.300%, 86.300%, 86.300%, 86.300%\n",
      "Average: 86.300%\n",
      "Class 5\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.444%, 86.444%, 86.444%, 86.444%, 86.444%, 86.444%, 86.444%, 86.444%, 86.444%, 86.444%\n",
      "Average: 86.444%\n",
      "        test:\n",
      "            87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%\n",
      "Average: 87.000%\n",
      "Class 6\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%\n",
      "Average: 87.000%\n",
      "        test:\n",
      "            86.233%, 86.233%, 86.233%, 86.233%, 86.233%, 86.233%, 86.233%, 86.233%, 86.233%, 86.233%\n",
      "Average: 86.233%\n",
      "Class 7\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.489%, 86.489%, 86.489%, 86.489%, 86.489%, 86.489%, 86.489%, 86.489%, 86.489%, 86.489%\n",
      "Average: 86.489%\n",
      "        test:\n",
      "            86.933%, 86.933%, 86.933%, 86.933%, 86.933%, 86.933%, 86.933%, 86.933%, 86.933%, 86.933%\n",
      "Average: 86.933%\n",
      "Class 8\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.111%, 87.111%, 87.111%, 87.111%, 87.111%, 87.111%, 87.111%, 87.111%, 87.111%, 87.111%\n",
      "Average: 87.111%\n",
      "        test:\n",
      "            85.300%, 85.300%, 85.300%, 85.300%, 85.300%, 85.300%, 85.300%, 85.300%, 85.300%, 85.300%\n",
      "Average: 85.300%\n",
      "Class 9\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%, 87.000%\n",
      "Average: 87.000%\n",
      "        test:\n",
      "            86.200%, 86.200%, 86.200%, 86.200%, 86.200%, 86.200%, 86.200%, 86.200%, 86.200%, 86.200%\n",
      "Average: 86.200%\n",
      "Class 10\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.644%, 86.644%, 86.644%, 86.644%, 86.644%, 86.644%, 86.644%, 86.644%, 86.644%, 86.644%\n",
      "Average: 86.644%\n",
      "        test:\n",
      "            86.700%, 86.700%, 86.700%, 86.700%, 86.700%, 86.700%, 86.700%, 86.700%, 86.700%, 86.700%\n",
      "Average: 86.700%\n",
      "Class 11\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%\n",
      "Average: 86.667%\n",
      "        test:\n",
      "            86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%\n",
      "Average: 86.667%\n",
      "Class 12\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.333%, 86.333%, 86.333%, 86.333%, 86.333%, 86.333%, 86.333%, 86.333%, 86.333%, 86.333%\n",
      "Average: 86.333%\n",
      "        test:\n",
      "            87.167%, 87.167%, 87.167%, 87.167%, 87.167%, 87.167%, 87.167%, 87.167%, 87.167%, 87.167%\n",
      "Average: 87.167%\n",
      "Class 13\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.956%, 86.956%, 86.956%, 86.956%, 86.956%, 86.956%, 86.956%, 86.956%, 86.956%, 86.956%\n",
      "Average: 86.956%\n",
      "        test:\n",
      "            85.933%, 85.933%, 85.933%, 85.933%, 85.933%, 85.933%, 85.933%, 85.933%, 85.933%, 85.933%\n",
      "Average: 85.933%\n",
      "Class 14\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.467%, 86.467%, 86.467%, 86.467%, 86.467%, 86.467%, 86.467%, 86.467%, 86.467%, 86.467%\n",
      "Average: 86.467%\n",
      "        test:\n",
      "            86.967%, 86.967%, 86.967%, 86.967%, 86.967%, 86.967%, 86.967%, 86.967%, 86.967%, 86.967%\n",
      "Average: 86.967%\n",
      "Class 0\n",
      "    accuracies:\n",
      "        train:\n",
      "            88.552%, 88.552%, 88.552%, 88.552%, 88.552%, 88.552%, 88.552%, 88.552%, 88.552%, 88.552%\n",
      "Average: 88.552%\n",
      "        test:\n",
      "            86.222%, 86.222%, 86.222%, 86.222%, 86.222%, 86.222%, 86.222%, 86.222%, 86.222%, 86.222%\n",
      "Average: 86.222%\n",
      "Class 1\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.438%, 86.438%, 86.438%, 86.438%, 86.438%, 86.438%, 86.438%, 86.438%, 86.438%, 86.438%\n",
      "Average: 86.438%\n",
      "        test:\n",
      "            87.200%, 87.200%, 87.200%, 87.200%, 87.200%, 87.200%, 87.200%, 87.200%, 87.200%, 87.200%\n",
      "Average: 87.200%\n",
      "Class 2\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.705%, 86.705%, 86.705%, 86.705%, 86.705%, 86.705%, 86.705%, 86.705%, 86.705%, 86.705%\n",
      "Average: 86.705%\n",
      "        test:\n",
      "            86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%\n",
      "Average: 86.578%\n",
      "Class 3\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.610%, 86.610%, 86.610%, 86.610%, 86.610%, 86.610%, 86.610%, 86.610%, 86.610%, 86.610%\n",
      "Average: 86.610%\n",
      "        test:\n",
      "            87.289%, 87.289%, 87.289%, 87.289%, 87.289%, 87.289%, 87.289%, 87.289%, 87.289%, 87.289%\n",
      "Average: 87.289%\n",
      "Class 4\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.257%, 87.257%, 87.257%, 87.257%, 87.257%, 87.257%, 87.257%, 87.257%, 87.257%, 87.257%\n",
      "Average: 87.257%\n",
      "        test:\n",
      "            85.689%, 85.689%, 85.689%, 85.689%, 85.689%, 85.689%, 85.689%, 85.689%, 85.689%, 85.689%\n",
      "Average: 85.689%\n",
      "Class 5\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.362%, 86.362%, 86.362%, 86.362%, 86.362%, 86.362%, 86.362%, 86.362%, 86.362%, 86.362%\n",
      "Average: 86.362%\n",
      "        test:\n",
      "            87.378%, 87.378%, 87.378%, 87.378%, 87.378%, 87.378%, 87.378%, 87.378%, 87.378%, 87.378%\n",
      "Average: 87.378%\n",
      "Class 6\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.971%, 86.971%, 86.971%, 86.971%, 86.971%, 86.971%, 86.971%, 86.971%, 86.971%, 86.971%\n",
      "Average: 86.971%\n",
      "        test:\n",
      "            86.044%, 86.044%, 86.044%, 86.044%, 86.044%, 86.044%, 86.044%, 86.044%, 86.044%, 86.044%\n",
      "Average: 86.044%\n",
      "Class 7\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%\n",
      "Average: 86.267%\n",
      "        test:\n",
      "            87.600%, 87.600%, 87.600%, 87.600%, 87.600%, 87.600%, 87.600%, 87.600%, 87.600%, 87.600%\n",
      "Average: 87.600%\n",
      "Class 8\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.143%, 87.143%, 87.143%, 87.143%, 87.143%, 87.143%, 87.143%, 87.143%, 87.143%, 87.143%\n",
      "Average: 87.143%\n",
      "        test:\n",
      "            85.556%, 85.556%, 85.556%, 85.556%, 85.556%, 85.556%, 85.556%, 85.556%, 85.556%, 85.556%\n",
      "Average: 85.556%\n",
      "Class 9\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.895%, 86.895%, 86.895%, 86.895%, 86.895%, 86.895%, 86.895%, 86.895%, 86.895%, 86.895%\n",
      "Average: 86.895%\n",
      "        test:\n",
      "            86.133%, 86.133%, 86.133%, 86.133%, 86.133%, 86.133%, 86.133%, 86.133%, 86.133%, 86.133%\n",
      "Average: 86.133%\n",
      "Class 10\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.705%, 86.705%, 86.705%, 86.705%, 86.705%, 86.705%, 86.705%, 86.705%, 86.705%, 86.705%\n",
      "Average: 86.705%\n",
      "        test:\n",
      "            86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%\n",
      "Average: 86.578%\n",
      "Class 11\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.495%, 86.495%, 86.495%, 86.495%, 86.495%, 86.495%, 86.495%, 86.495%, 86.495%, 86.495%\n",
      "Average: 86.495%\n",
      "        test:\n",
      "            87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%\n",
      "Average: 87.067%\n",
      "Class 12\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.514%, 86.514%, 86.514%, 86.514%, 86.514%, 86.514%, 86.514%, 86.514%, 86.514%, 86.514%\n",
      "Average: 86.514%\n",
      "        test:\n",
      "            87.022%, 87.022%, 87.022%, 87.022%, 87.022%, 87.022%, 87.022%, 87.022%, 87.022%, 87.022%\n",
      "Average: 87.022%\n",
      "Class 13\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.048%, 87.048%, 87.048%, 87.048%, 87.048%, 87.048%, 87.048%, 87.048%, 87.048%, 87.048%\n",
      "Average: 87.048%\n",
      "        test:\n",
      "            85.822%, 85.822%, 85.822%, 85.822%, 85.822%, 85.822%, 85.822%, 85.822%, 85.822%, 85.822%\n",
      "Average: 85.822%\n",
      "Class 14\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.495%, 86.495%, 86.495%, 86.495%, 86.495%, 86.495%, 86.495%, 86.495%, 86.495%, 86.495%\n",
      "Average: 86.495%\n",
      "        test:\n",
      "            87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%\n",
      "Average: 87.067%\n",
      "Class 0\n",
      "    accuracies:\n",
      "        train:\n",
      "            88.683%, 88.683%, 88.683%, 88.683%, 88.683%, 88.683%, 88.683%, 88.683%, 88.683%, 88.683%\n",
      "Average: 88.683%\n",
      "        test:\n",
      "            87.733%, 87.733%, 87.733%, 87.733%, 87.733%, 87.733%, 87.733%, 87.733%, 87.733%, 87.733%\n",
      "Average: 87.733%\n",
      "Class 1\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.567%, 86.567%, 86.567%, 86.567%, 86.567%, 86.567%, 86.567%, 86.567%, 86.567%, 86.567%\n",
      "Average: 86.567%\n",
      "        test:\n",
      "            87.133%, 87.133%, 87.133%, 87.133%, 87.133%, 87.133%, 87.133%, 87.133%, 87.133%, 87.133%\n",
      "Average: 87.133%\n",
      "Class 2\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.883%, 86.883%, 86.883%, 86.883%, 86.883%, 86.883%, 86.883%, 86.883%, 86.883%, 86.883%\n",
      "Average: 86.883%\n",
      "        test:\n",
      "            85.933%, 85.933%, 85.933%, 85.933%, 85.933%, 85.933%, 85.933%, 85.933%, 85.933%, 85.933%\n",
      "Average: 85.933%\n",
      "Class 3\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.483%, 86.483%, 86.483%, 86.483%, 86.483%, 86.483%, 86.483%, 86.483%, 86.483%, 86.483%\n",
      "Average: 86.483%\n",
      "        test:\n",
      "            88.133%, 88.133%, 88.133%, 88.133%, 88.133%, 88.133%, 88.133%, 88.133%, 88.133%, 88.133%\n",
      "Average: 88.133%\n",
      "Class 4\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.533%, 87.533%, 87.533%, 87.533%, 87.533%, 87.533%, 87.533%, 87.533%, 87.533%, 87.533%\n",
      "Average: 87.533%\n",
      "        test:\n",
      "            85.067%, 85.067%, 85.067%, 85.067%, 85.067%, 85.067%, 85.067%, 85.067%, 85.067%, 85.067%\n",
      "Average: 85.067%\n",
      "Class 5\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.483%, 86.483%, 86.483%, 86.483%, 86.483%, 86.483%, 86.483%, 86.483%, 86.483%, 86.483%\n",
      "Average: 86.483%\n",
      "        test:\n",
      "            87.400%, 87.400%, 87.400%, 87.400%, 87.400%, 87.400%, 87.400%, 87.400%, 87.400%, 87.400%\n",
      "Average: 87.400%\n",
      "Class 6\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.967%, 86.967%, 86.967%, 86.967%, 86.967%, 86.967%, 86.967%, 86.967%, 86.967%, 86.967%\n",
      "Average: 86.967%\n",
      "        test:\n",
      "            85.533%, 85.533%, 85.533%, 85.533%, 85.533%, 85.533%, 85.533%, 85.533%, 85.533%, 85.533%\n",
      "Average: 85.533%\n",
      "Class 7\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%\n",
      "Average: 86.267%\n",
      "        test:\n",
      "            88.267%, 88.267%, 88.267%, 88.267%, 88.267%, 88.267%, 88.267%, 88.267%, 88.267%, 88.267%\n",
      "Average: 88.267%\n",
      "Class 8\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.817%, 86.817%, 86.817%, 86.817%, 86.817%, 86.817%, 86.817%, 86.817%, 86.817%, 86.817%\n",
      "Average: 86.817%\n",
      "        test:\n",
      "            86.200%, 86.200%, 86.200%, 86.200%, 86.200%, 86.200%, 86.200%, 86.200%, 86.200%, 86.200%\n",
      "Average: 86.200%\n",
      "Class 9\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.833%, 86.833%, 86.833%, 86.833%, 86.833%, 86.833%, 86.833%, 86.833%, 86.833%, 86.833%\n",
      "Average: 86.833%\n",
      "        test:\n",
      "            86.000%, 86.000%, 86.000%, 86.000%, 86.000%, 86.000%, 86.000%, 86.000%, 86.000%, 86.000%\n",
      "Average: 86.000%\n",
      "Class 10\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.867%, 86.867%, 86.867%, 86.867%, 86.867%, 86.867%, 86.867%, 86.867%, 86.867%, 86.867%\n",
      "Average: 86.867%\n",
      "        test:\n",
      "            85.867%, 85.867%, 85.867%, 85.867%, 85.867%, 85.867%, 85.867%, 85.867%, 85.867%, 85.867%\n",
      "Average: 85.867%\n",
      "Class 11\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.633%, 86.633%, 86.633%, 86.633%, 86.633%, 86.633%, 86.633%, 86.633%, 86.633%, 86.633%\n",
      "Average: 86.633%\n",
      "        test:\n",
      "            86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%\n",
      "Average: 86.800%\n",
      "Class 12\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.417%, 86.417%, 86.417%, 86.417%, 86.417%, 86.417%, 86.417%, 86.417%, 86.417%, 86.417%\n",
      "Average: 86.417%\n",
      "        test:\n",
      "            87.667%, 87.667%, 87.667%, 87.667%, 87.667%, 87.667%, 87.667%, 87.667%, 87.667%, 87.667%\n",
      "Average: 87.667%\n",
      "Class 13\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.817%, 86.817%, 86.817%, 86.817%, 86.817%, 86.817%, 86.817%, 86.817%, 86.817%, 86.817%\n",
      "Average: 86.817%\n",
      "        test:\n",
      "            86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%\n",
      "Average: 86.267%\n",
      "Class 14\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.517%, 86.517%, 86.517%, 86.517%, 86.517%, 86.517%, 86.517%, 86.517%, 86.517%, 86.517%\n",
      "Average: 86.517%\n",
      "        test:\n",
      "            87.267%, 87.267%, 87.267%, 87.267%, 87.267%, 87.267%, 87.267%, 87.267%, 87.267%, 87.267%\n",
      "Average: 87.267%\n",
      "Class 0\n",
      "    accuracies:\n",
      "        train:\n",
      "            88.296%, 88.296%, 88.296%, 88.296%, 88.296%, 88.296%, 88.296%, 88.296%, 88.296%, 88.296%\n",
      "Average: 88.296%\n",
      "        test:\n",
      "            88.400%, 88.400%, 88.400%, 88.400%, 88.400%, 88.400%, 88.400%, 88.400%, 88.400%, 88.400%\n",
      "Average: 88.400%\n",
      "Class 1\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.533%, 86.533%, 86.533%, 86.533%, 86.533%, 86.533%, 86.533%, 86.533%, 86.533%, 86.533%\n",
      "Average: 86.533%\n",
      "        test:\n",
      "            88.000%, 88.000%, 88.000%, 88.000%, 88.000%, 88.000%, 88.000%, 88.000%, 88.000%, 88.000%\n",
      "Average: 88.000%\n",
      "Class 2\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%\n",
      "Average: 86.667%\n",
      "        test:\n",
      "            86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%, 86.667%\n",
      "Average: 86.667%\n",
      "Class 3\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%\n",
      "Average: 86.652%\n",
      "        test:\n",
      "            87.867%, 87.867%, 87.867%, 87.867%, 87.867%, 87.867%, 87.867%, 87.867%, 87.867%, 87.867%\n",
      "Average: 87.867%\n",
      "Class 4\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.230%, 87.230%, 87.230%, 87.230%, 87.230%, 87.230%, 87.230%, 87.230%, 87.230%, 87.230%\n",
      "Average: 87.230%\n",
      "        test:\n",
      "            85.333%, 85.333%, 85.333%, 85.333%, 85.333%, 85.333%, 85.333%, 85.333%, 85.333%, 85.333%\n",
      "Average: 85.333%\n",
      "Class 5\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%, 86.578%\n",
      "Average: 86.578%\n",
      "        test:\n",
      "            87.467%, 87.467%, 87.467%, 87.467%, 87.467%, 87.467%, 87.467%, 87.467%, 87.467%, 87.467%\n",
      "Average: 87.467%\n",
      "Class 6\n",
      "    accuracies:\n",
      "        train:\n",
      "            87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%, 87.067%\n",
      "Average: 87.067%\n",
      "        test:\n",
      "            83.333%, 83.333%, 83.333%, 83.333%, 83.333%, 83.333%, 83.333%, 83.333%, 83.333%, 83.333%\n",
      "Average: 83.333%\n",
      "Class 7\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.400%, 86.400%, 86.400%, 86.400%, 86.400%, 86.400%, 86.400%, 86.400%, 86.400%, 86.400%\n",
      "Average: 86.400%\n",
      "        test:\n",
      "            89.067%, 89.067%, 89.067%, 89.067%, 89.067%, 89.067%, 89.067%, 89.067%, 89.067%, 89.067%\n",
      "Average: 89.067%\n",
      "Class 8\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%\n",
      "Average: 86.652%\n",
      "        test:\n",
      "            86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%\n",
      "Average: 86.800%\n",
      "Class 9\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.874%, 86.874%, 86.874%, 86.874%, 86.874%, 86.874%, 86.874%, 86.874%, 86.874%, 86.874%\n",
      "Average: 86.874%\n",
      "        test:\n",
      "            84.800%, 84.800%, 84.800%, 84.800%, 84.800%, 84.800%, 84.800%, 84.800%, 84.800%, 84.800%\n",
      "Average: 84.800%\n",
      "Class 10\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.711%, 86.711%, 86.711%, 86.711%, 86.711%, 86.711%, 86.711%, 86.711%, 86.711%, 86.711%\n",
      "Average: 86.711%\n",
      "        test:\n",
      "            86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%, 86.267%\n",
      "Average: 86.267%\n",
      "Class 11\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.681%, 86.681%, 86.681%, 86.681%, 86.681%, 86.681%, 86.681%, 86.681%, 86.681%, 86.681%\n",
      "Average: 86.681%\n",
      "        test:\n",
      "            86.533%, 86.533%, 86.533%, 86.533%, 86.533%, 86.533%, 86.533%, 86.533%, 86.533%, 86.533%\n",
      "Average: 86.533%\n",
      "Class 12\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%, 86.652%\n",
      "Average: 86.652%\n",
      "        test:\n",
      "            86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%, 86.800%\n",
      "Average: 86.800%\n",
      "Class 13\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.756%, 86.756%, 86.756%, 86.756%, 86.756%, 86.756%, 86.756%, 86.756%, 86.756%, 86.756%\n",
      "Average: 86.756%\n",
      "        test:\n",
      "            86.400%, 86.400%, 86.400%, 86.400%, 86.400%, 86.400%, 86.400%, 86.400%, 86.400%, 86.400%\n",
      "Average: 86.400%\n",
      "Class 14\n",
      "    accuracies:\n",
      "        train:\n",
      "            86.415%, 86.415%, 86.415%, 86.415%, 86.415%, 86.415%, 86.415%, 86.415%, 86.415%, 86.415%\n",
      "Average: 86.415%\n",
      "        test:\n",
      "            88.933%, 88.933%, 88.933%, 88.933%, 88.933%, 88.933%, 88.933%, 88.933%, 88.933%, 88.933%\n",
      "Average: 88.933%\n"
     ]
    }
   ],
   "source": [
    "# from time import time\n",
    "\n",
    "# trainSizes = [x/10 for x in range(1,10)]\n",
    "# hard_start = time()\n",
    "\n",
    "# def print_dict(dictionary, sep=''):\n",
    "#     for key in dictionary.keys():\n",
    "#         new_sep = sep+'    '\n",
    "#         if type(key) is int:\n",
    "#             print(f\"Class {key}\")\n",
    "#         else:\n",
    "#             print(f\"{sep}{key}:\")\n",
    "#         if type(dictionary[key]) is dict:\n",
    "#             print_dict(dictionary[key], sep=new_sep)\n",
    "#         elif key == \"losses\":\n",
    "#             val_str = \"\"\n",
    "#             for i in range(len(dictionary[key])-1):\n",
    "#                 val_str += f\"{dictionary[key][i]:.2f}, \"\n",
    "#             val_str += f\"{dictionary[key][-1]:.2f}\"\n",
    "#             print(f\"{new_sep}{val_str}\")\n",
    "#             print(f\"Average: {sum(dictionary[key])/len(dictionary[key]):.2f}\")\n",
    "#         elif type(dictionary[key]) is list:\n",
    "#             val_str = \"\"\n",
    "#             for i in range(len(dictionary[key])-1):\n",
    "#                 val_str += f\"{dictionary[key][i]:.3%}, \"\n",
    "#             val_str += f\"{dictionary[key][-1]:.3%}\"\n",
    "#             print(f\"{new_sep}{val_str}\")\n",
    "#             print(f\"Average: {sum(dictionary[key])/len(dictionary[key]):.3%}\")\n",
    "#         else:\n",
    "#             print(f\"{new_sep}{dictionary[key]}\")\n",
    "\n",
    "# def thread_loss(H, Y, classifier):\n",
    "#     true_y = np.array(Y)\n",
    "#     return (sum([max(0, 1 - (true_y.reshape(1, true_y.shape[0]) @ np.array(wl.y_pred))/len(wl.y_pred)) for wl in H])/len(H))[0]\n",
    "            \n",
    "# def runner(pnum, ptracker, rcount, Xtrain, Ytrain, Xtest, Ytest, classifier):\n",
    "#     H = []\n",
    "#     Weak_Learners = []\n",
    "#     for i in range(10):\n",
    "#         model = ShallowTree()\n",
    "#         Weak_Learners.append(WeakLearner(model, classifier))\n",
    "#     weights = np.array([1/len(Xtrain) for _ in range(len(Xtrain))])\n",
    "#     for r in range(10):\n",
    "#         ptracker[rcount][pnum][\"accuracies\"][\"train\"].append(run(Weak_Learners, Xtrain, Ytrain, H, weights))\n",
    "#         ptracker[rcount][pnum][\"losses\"].append(thread_loss(H, Ytrain, classifier))\n",
    "#         ptracker[rcount][pnum][\"accuracies\"][\"test\"].append(H_accuracy(H, Xtest, Ytest))\n",
    "\n",
    "# def f(pnum, ptracker, rcount, split, X, Y):\n",
    "#     for i in range(pnum):\n",
    "#         ptracker[rcount][i] = {}\n",
    "#         ptracker[rcount][i][\"accuracies\"] = {\"train\": [], \"test\": []}\n",
    "#         ptracker[rcount][i][\"losses\"] = []\n",
    "#     Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, train_size=split, random_state = 2021)\n",
    "#     Ytrain_classes = [classify(Ytrain, i) for i in range(15)]\n",
    "#     Ytest_classes = [classify(Ytest, i) for i in range(15)]\n",
    "#     jobs = []\n",
    "#     for i in range(15):\n",
    "#         proc = threading.Thread(target=runner, args=(i, ptracker, rcount, Xtrain, Ytrain_classes[i], Xtest, Ytest_classes[i], i), name=f\"Thread {i}\")\n",
    "#         jobs.append(proc)\n",
    "#         proc.start()\n",
    "    \n",
    "#     for count,p in enumerate(jobs):\n",
    "#         p.join()\n",
    "\n",
    "# ptrackers = [{} for _ in trainSizes]\n",
    "# for i,ratio in enumerate(trainSizes):\n",
    "#     f(15, ptrackers, i, ratio, X, Y)\n",
    "# for i in range(len(ptrackers)):\n",
    "#     print(f\"Ratio: {trainSizes[i]}\")\n",
    "#     print_dict(ptrackers[i])\n",
    "# # ratio_threads = []\n",
    "# # for i,ratio in enumerate(trainSizes):\n",
    "# #     print(f\"Running ratio: {ratio:.0%}\")\n",
    "# #     proc = threading.Thread(target=f, args=(15, ptrackers, i, ratio, X, Y))\n",
    "# #     ratio_threads.append(proc)\n",
    "# #     proc.start()\n",
    "\n",
    "# # for i, proc in enumerate(ratio_threads):\n",
    "# #     proc.join()\n",
    "# #     print_dict(ptrackers[i])\n",
    "# print(f\"Took {time()-hard_start} seconds to run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration starting after 0.00 seconds\n",
      "Iteration 25 ended after 48.90 seconds\n",
      "Iteration 50 ended after 93.76 seconds\n",
      "Iteration 75 ended after 138.97 seconds\n",
      "Iteration 100 ended after 184.51 seconds\n",
      "Iteration 125 ended after 233.96 seconds\n",
      "Iteration 150 ended after 287.99 seconds\n",
      "Iteration 175 ended after 341.23 seconds\n",
      "Iteration 200 ended after 391.76 seconds\n",
      "Iteration 225 ended after 439.42 seconds\n",
      "Iteration 250 ended after 486.42 seconds\n",
      "Iteration 275 ended after 535.82 seconds\n",
      "Iteration 300 ended after 585.30 seconds\n",
      "Iteration 325 ended after 629.76 seconds\n",
      "Iteration 350 ended after 673.98 seconds\n",
      "Iteration 375 ended after 718.58 seconds\n",
      "Iteration 400 ended after 762.27 seconds\n",
      "Iteration 425 ended after 807.13 seconds\n",
      "Iteration 450 ended after 853.25 seconds\n",
      "Iteration 475 ended after 897.14 seconds\n",
      "Iteration 500 ended after 942.55 seconds\n",
      "Ratio: 10.00%\n",
      "\t Train Accuracy: 12.70%\n",
      "Ratio: 10.00%\n",
      "\t Test Accuracy: 11.30%\n",
      "950.82 seconds elapsed\n",
      "Iteration starting after 0.00 seconds\n",
      "Iteration 25 ended after 98.13 seconds\n",
      "Iteration 50 ended after 194.22 seconds\n",
      "Iteration 75 ended after 298.11 seconds\n",
      "Iteration 100 ended after 395.10 seconds\n",
      "Iteration 125 ended after 492.46 seconds\n",
      "Iteration 150 ended after 606.44 seconds\n",
      "Iteration 175 ended after 705.77 seconds\n",
      "Iteration 200 ended after 802.09 seconds\n",
      "Iteration 225 ended after 900.57 seconds\n",
      "Iteration 250 ended after 1003.04 seconds\n",
      "Iteration 275 ended after 1101.16 seconds\n",
      "Iteration 300 ended after 1210.83 seconds\n",
      "Iteration 325 ended after 1314.18 seconds\n",
      "Iteration 350 ended after 1423.12 seconds\n",
      "Iteration 375 ended after 1526.16 seconds\n",
      "Iteration 400 ended after 1624.78 seconds\n",
      "Iteration 425 ended after 1705.06 seconds\n",
      "Iteration 450 ended after 1784.80 seconds\n",
      "Iteration 475 ended after 1865.88 seconds\n",
      "Iteration 500 ended after 1945.75 seconds\n",
      "Ratio: 20.00%\n",
      "\t Train Accuracy: 9.60%\n",
      "Ratio: 20.00%\n",
      "\t Test Accuracy: 10.70%\n",
      "1952.11 seconds elapsed\n",
      "Iteration starting after 0.00 seconds\n",
      "Iteration 25 ended after 120.38 seconds\n",
      "Iteration 50 ended after 240.04 seconds\n",
      "Iteration 75 ended after 359.94 seconds\n",
      "Iteration 100 ended after 479.50 seconds\n",
      "Iteration 125 ended after 600.37 seconds\n",
      "Iteration 150 ended after 719.72 seconds\n",
      "Iteration 175 ended after 839.64 seconds\n",
      "Iteration 200 ended after 959.35 seconds\n",
      "Iteration 225 ended after 1078.85 seconds\n",
      "Iteration 250 ended after 1198.93 seconds\n",
      "Iteration 275 ended after 1318.67 seconds\n",
      "Iteration 300 ended after 1438.59 seconds\n",
      "Iteration 325 ended after 1558.83 seconds\n",
      "Iteration 350 ended after 1678.29 seconds\n",
      "Iteration 375 ended after 1798.74 seconds\n",
      "Iteration 400 ended after 1920.27 seconds\n",
      "Iteration 425 ended after 2040.58 seconds\n",
      "Iteration 450 ended after 2160.19 seconds\n",
      "Iteration 475 ended after 2279.79 seconds\n",
      "Iteration 500 ended after 2401.32 seconds\n",
      "Ratio: 30.00%\n",
      "\t Train Accuracy: 10.20%\n",
      "Ratio: 30.00%\n",
      "\t Test Accuracy: 11.80%\n",
      "2407.62 seconds elapsed\n",
      "Iteration starting after 0.00 seconds\n",
      "Iteration 25 ended after 161.73 seconds\n",
      "Iteration 50 ended after 322.81 seconds\n",
      "Iteration 75 ended after 484.42 seconds\n",
      "Iteration 100 ended after 645.98 seconds\n",
      "Iteration 125 ended after 806.51 seconds\n",
      "Iteration 150 ended after 966.92 seconds\n",
      "Iteration 175 ended after 1127.90 seconds\n",
      "Iteration 200 ended after 1289.76 seconds\n",
      "Iteration 225 ended after 1449.87 seconds\n",
      "Iteration 250 ended after 1610.82 seconds\n",
      "Iteration 275 ended after 1771.67 seconds\n",
      "Iteration 300 ended after 1933.96 seconds\n",
      "Iteration 325 ended after 2094.88 seconds\n",
      "Iteration 350 ended after 2256.14 seconds\n",
      "Iteration 375 ended after 2415.94 seconds\n",
      "Iteration 400 ended after 2576.91 seconds\n",
      "Iteration 425 ended after 2738.04 seconds\n",
      "Iteration 450 ended after 2898.50 seconds\n",
      "Iteration 475 ended after 3062.32 seconds\n",
      "Iteration 500 ended after 3223.31 seconds\n",
      "Ratio: 40.00%\n",
      "\t Train Accuracy: 12.00%\n",
      "Ratio: 40.00%\n",
      "\t Test Accuracy: 10.50%\n",
      "3229.79 seconds elapsed\n",
      "Iteration starting after 0.00 seconds\n",
      "Iteration 25 ended after 206.01 seconds\n",
      "Iteration 50 ended after 410.44 seconds\n",
      "Iteration 75 ended after 613.16 seconds\n",
      "Iteration 100 ended after 817.17 seconds\n",
      "Iteration 125 ended after 1020.51 seconds\n",
      "Iteration 150 ended after 1223.59 seconds\n",
      "Iteration 175 ended after 1427.18 seconds\n",
      "Iteration 200 ended after 1631.04 seconds\n",
      "Iteration 225 ended after 1833.41 seconds\n",
      "Iteration 250 ended after 2037.55 seconds\n",
      "Iteration 275 ended after 2242.70 seconds\n",
      "Iteration 300 ended after 2446.25 seconds\n",
      "Iteration 325 ended after 2649.85 seconds\n",
      "Iteration 350 ended after 2853.41 seconds\n",
      "Iteration 375 ended after 3057.05 seconds\n",
      "Iteration 400 ended after 3259.64 seconds\n",
      "Iteration 425 ended after 3465.39 seconds\n",
      "Iteration 450 ended after 3671.66 seconds\n",
      "Iteration 475 ended after 3874.14 seconds\n",
      "Iteration 500 ended after 4079.54 seconds\n",
      "Ratio: 50.00%\n",
      "\t Train Accuracy: 8.80%\n",
      "Ratio: 50.00%\n",
      "\t Test Accuracy: 10.70%\n",
      "4085.71 seconds elapsed\n",
      "Iteration starting after 0.00 seconds\n",
      "Iteration 25 ended after 245.60 seconds\n",
      "Iteration 50 ended after 491.82 seconds\n",
      "Iteration 75 ended after 737.45 seconds\n",
      "Iteration 100 ended after 983.53 seconds\n",
      "Iteration 125 ended after 1246.08 seconds\n",
      "Iteration 150 ended after 1495.88 seconds\n",
      "Iteration 175 ended after 1742.98 seconds\n",
      "Iteration 200 ended after 1990.95 seconds\n",
      "Iteration 225 ended after 2240.68 seconds\n",
      "Iteration 250 ended after 2490.65 seconds\n",
      "Iteration 275 ended after 2747.38 seconds\n",
      "Iteration 300 ended after 3028.41 seconds\n",
      "Iteration 325 ended after 3310.34 seconds\n",
      "Iteration 350 ended after 3593.51 seconds\n",
      "Iteration 375 ended after 3876.67 seconds\n",
      "Iteration 400 ended after 4170.75 seconds\n",
      "Iteration 425 ended after 4459.83 seconds\n",
      "Iteration 450 ended after 4714.64 seconds\n",
      "Iteration 475 ended after 4965.43 seconds\n",
      "Iteration 500 ended after 5215.60 seconds\n",
      "Ratio: 60.00%\n",
      "\t Train Accuracy: 9.30%\n",
      "Ratio: 60.00%\n",
      "\t Test Accuracy: 10.60%\n",
      "5221.76 seconds elapsed\n",
      "Iteration starting after 0.00 seconds\n",
      "Iteration 25 ended after 293.00 seconds\n",
      "Iteration 50 ended after 586.33 seconds\n",
      "Iteration 75 ended after 881.06 seconds\n",
      "Iteration 100 ended after 1172.44 seconds\n",
      "Iteration 125 ended after 1465.33 seconds\n",
      "Iteration 150 ended after 1759.59 seconds\n",
      "Iteration 175 ended after 2052.03 seconds\n",
      "Iteration 200 ended after 2342.29 seconds\n",
      "Iteration 225 ended after 2633.98 seconds\n",
      "Iteration 250 ended after 2924.21 seconds\n",
      "Iteration 275 ended after 3214.09 seconds\n",
      "Iteration 300 ended after 3504.15 seconds\n",
      "Iteration 325 ended after 3795.89 seconds\n",
      "Iteration 350 ended after 4086.29 seconds\n",
      "Iteration 375 ended after 4377.17 seconds\n",
      "Iteration 400 ended after 4667.16 seconds\n",
      "Iteration 425 ended after 4959.41 seconds\n",
      "Iteration 450 ended after 5249.38 seconds\n",
      "Iteration 475 ended after 5539.63 seconds\n",
      "Iteration 500 ended after 5829.99 seconds\n",
      "Ratio: 70.00%\n",
      "\t Train Accuracy: 8.90%\n",
      "Ratio: 70.00%\n",
      "\t Test Accuracy: 11.90%\n",
      "5836.29 seconds elapsed\n",
      "Iteration starting after 0.00 seconds\n",
      "Iteration 25 ended after 332.95 seconds\n",
      "Iteration 50 ended after 665.52 seconds\n",
      "Iteration 75 ended after 999.58 seconds\n",
      "Iteration 100 ended after 1332.66 seconds\n",
      "Iteration 125 ended after 1667.11 seconds\n",
      "Iteration 150 ended after 2002.23 seconds\n",
      "Iteration 175 ended after 2335.56 seconds\n",
      "Iteration 200 ended after 2671.60 seconds\n",
      "Iteration 225 ended after 3008.44 seconds\n",
      "Iteration 250 ended after 3343.33 seconds\n",
      "Iteration 275 ended after 3678.55 seconds\n",
      "Iteration 300 ended after 4013.50 seconds\n",
      "Iteration 325 ended after 4347.50 seconds\n",
      "Iteration 350 ended after 4682.77 seconds\n",
      "Iteration 375 ended after 5016.43 seconds\n",
      "Iteration 400 ended after 5353.27 seconds\n",
      "Iteration 425 ended after 5688.24 seconds\n",
      "Iteration 450 ended after 6022.41 seconds\n",
      "Iteration 475 ended after 6358.30 seconds\n",
      "Iteration 500 ended after 6692.86 seconds\n",
      "Ratio: 80.00%\n",
      "\t Train Accuracy: 10.50%\n",
      "Ratio: 80.00%\n",
      "\t Test Accuracy: 10.90%\n",
      "6699.00 seconds elapsed\n",
      "Iteration starting after 0.00 seconds\n",
      "Iteration 25 ended after 403.26 seconds\n",
      "Iteration 50 ended after 783.30 seconds\n",
      "Iteration 75 ended after 1161.49 seconds\n",
      "Iteration 100 ended after 1541.11 seconds\n",
      "Iteration 125 ended after 1918.78 seconds\n",
      "Iteration 150 ended after 2299.26 seconds\n",
      "Iteration 175 ended after 2679.08 seconds\n",
      "Iteration 200 ended after 3058.92 seconds\n",
      "Iteration 225 ended after 3443.75 seconds\n",
      "Iteration 250 ended after 3825.70 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 275 ended after 4205.97 seconds\n",
      "Iteration 300 ended after 4585.29 seconds\n",
      "Iteration 325 ended after 4966.40 seconds\n",
      "Iteration 350 ended after 5347.50 seconds\n",
      "Iteration 375 ended after 5728.93 seconds\n",
      "Iteration 400 ended after 6110.32 seconds\n",
      "Iteration 425 ended after 6489.50 seconds\n",
      "Iteration 450 ended after 6871.19 seconds\n",
      "Iteration 475 ended after 7253.00 seconds\n",
      "Iteration 500 ended after 7634.84 seconds\n",
      "Ratio: 90.00%\n",
      "\t Train Accuracy: 7.60%\n",
      "Ratio: 90.00%\n",
      "\t Test Accuracy: 8.50%\n",
      "7640.97 seconds elapsed\n",
      "38024.06 seconds to run\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Here we test the performace of our model with different amounts of training data \n",
    "\"\"\"\n",
    "from time import time\n",
    "\n",
    "trainSizes = [x / 10 for x in range(1, 10, 1)] # Create a list of [0.5, ..., 0.9] If x < 0.5 we get an out of bounds error on the weights\n",
    "\n",
    "hard_start = time()\n",
    "\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "for trainRatio in trainSizes:\n",
    "    start = time()\n",
    "    \n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, train_size=trainRatio, random_state=2021)\n",
    "    Ytrain_classes = []\n",
    "    Ytest_classes = []\n",
    "    if Ytrain.shape[1] != 1:\n",
    "        for i in range(Ytrain.shape[1]):\n",
    "            Ytrain_i = classify(Ytrain, i)\n",
    "            Ytrain_classes.append(Ytrain_i)\n",
    "            Ytest_i = classify(Ytest, i)\n",
    "            Ytest_classes.append(Ytest_i)\n",
    "    else:\n",
    "        Ytrain_classes = Ytrain.copy()\n",
    "        Ytest_classes = Ytest.copy()\n",
    "    \n",
    "    model = Boost(n_estimators=500, base_learner=ShallowTree()).fit(Xtrain,Ytrain, verbose=25)\n",
    "    \n",
    "#     train_accuracies = []\n",
    "#     test_accuracies = []\n",
    "#     for i in range(Ytrain.shape[1]):\n",
    "#         H = []\n",
    "#         Weak_Learners = []\n",
    "#         for _ in range(10):\n",
    "#             model = ShallowTree()\n",
    "#             model.fit(Xtrain, Ytrain_classes[0])\n",
    "#             Weak_Learners.append(WeakLearner(model, 0))\n",
    "\n",
    "#         weights = np.array([1/len(Xtrain) for _ in range(len(Xtrain))])\n",
    "#         train_local_accuracies = []\n",
    "#         test_local_accuracies = []\n",
    "#         for r in range(10):\n",
    "#             train_local_accuracies.append(run(Weak_Learners, Xtrain, Ytrain_classes[i], H, weights))\n",
    "#             print(f\"Loss on run {r}: {WL_loss(H, Ytrain_classes, i):.3f}\")\n",
    "#             test_local_accuracies.append(H_accuracy(H, Xtest, Ytest_classes[i]))\n",
    "\n",
    "#         train_accuracies.append(sum(train_local_accuracies) / len(train_local_accuracies))\n",
    "#         test_accuracies.append(sum(test_local_accuracies)/len(test_local_accuracies))\n",
    "        \n",
    "    train_acc = model.accuracy(model.predict(Xtrain[:1000,]),Ytrain[:1000,])\n",
    "    train_accuracy.append(train_acc)\n",
    "    print(f\"Ratio: {trainRatio:.2%}\\n\\t Train Accuracy: {train_acc:.2%}\")\n",
    "    test_acc = model.accuracy(model.predict(Xtest[:1000,]),Ytest[:1000,])\n",
    "    test_accuracy.append(test_acc)\n",
    "    print(f\"Ratio: {trainRatio:.2%}\\n\\t Test Accuracy: {test_acc:.2%}\")\n",
    "    print(f\"{time()-start:.2f} seconds elapsed\")\n",
    "    \n",
    "print(f\"{time()-hard_start:.2f} seconds to run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Ytrain.shape)\n",
    "# print(Ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent correct with training set and tree size 2: 82.10%\n",
      "Percent correct with test set and tree size 2: 82.49%\n",
      "685.31 seconds elapsed\n",
      "Percent correct with training set and tree size 3: 81.15%\n",
      "Percent correct with test set and tree size 3: 81.34%\n",
      "770.76 seconds elapsed\n",
      "Percent correct with training set and tree size 4: 80.59%\n",
      "Percent correct with test set and tree size 4: 80.99%\n",
      "848.00 seconds elapsed\n",
      "Percent correct with training set and tree size 5: 80.21%\n",
      "Percent correct with test set and tree size 5: 80.79%\n",
      "872.08 seconds elapsed\n",
      "Percent correct with training set and tree size 6: 79.90%\n",
      "Percent correct with test set and tree size 6: 80.59%\n",
      "962.80 seconds elapsed\n",
      "Percent correct with training set and tree size 7: 79.61%\n",
      "Percent correct with test set and tree size 7: 80.38%\n",
      "1051.88 seconds elapsed\n",
      "Percent correct with training set and tree size 8: 79.32%\n",
      "Percent correct with test set and tree size 8: 80.17%\n",
      "1139.44 seconds elapsed\n",
      "Percent correct with training set and tree size 9: 79.07%\n",
      "Percent correct with test set and tree size 9: 79.97%\n",
      "1230.19 seconds elapsed\n",
      "7560.57 seconds to run\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Now we vary the size of the trees\n",
    "We use 80% train, 20% test (The standard)\n",
    "\"\"\"\n",
    "hard_start = time()\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, train_size=0.8, random_state=2021)\n",
    "Ytrain_classes = []\n",
    "Ytest_classes = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for treeSize in range(1, 10):\n",
    "    start = time()\n",
    "    if Ytrain.shape[1] != 1:\n",
    "        for i in range(Ytrain.shape[1]):\n",
    "            Ytrain_i = classify(Ytrain, i)\n",
    "            Ytrain_classes.append(Ytrain_i)\n",
    "            Ytest_i = classify(Ytest, i)\n",
    "            Ytest_classes.append(Ytest_i)\n",
    "    else:\n",
    "        Ytrain_classes = Ytrain.copy()\n",
    "        Ytest_classes = Ytest.copy()\n",
    "        \n",
    "    model = Boost(n_estimators=250, base_learner=ShallowTree(treeSize)).fit(Xtrain,Ytrain)\n",
    "        \n",
    "#     for i in range(Ytrain.shape[1]):\n",
    "#         H_train = []\n",
    "#         H_test =[]\n",
    "#         Weak_Learners = []\n",
    "#         for _ in range(10):\n",
    "#             model = ShallowTree(treeSize)\n",
    "#             model.fit(Xtrain, Ytrain_classes[0])\n",
    "#             Weak_Learners.append(WeakLearner(model, 0))\n",
    "\n",
    "#         weights = np.array([1/len(Xtrain) for _ in range(len(Xtrain))])\n",
    "#         local_accuracies = []\n",
    "        \n",
    "#         for r in range(10):\n",
    "#             train_local_accuracies.append(run(Weak_Learners, Xtrain, Ytrain_classes[i], H_train, weights))\n",
    "#             test_local_accuracies.append(run(Weak_Learners, Xtest, Ytest_classes[i], H_test, weights))\n",
    "\n",
    "#         train_accuracies.append(sum(train_local_accuracies) / len(train_local_accuracies))\n",
    "#         test_accuracies.append(sum(test_local_accuracies)/len(test_local_accuracies))\n",
    "\n",
    "    train_acc = model.accuracy(model.predict(Xtrain),Ytrain)\n",
    "    train_accuracies.append(train_acc)\n",
    "    test_acc = model.accuracy(model.predict(Xtest),Ytest)\n",
    "    test_accuracies.append(test_acc)\n",
    "\n",
    "    print(f\"Percent correct with training set and tree size {treeSize}: {train_acc:.2%}\")\n",
    "    print(f\"Percent correct with test set and tree size {treeSize}: {test_acc/len(test_accuracies):.2%}\")\n",
    "    print(f\"{time()-start:.2f} seconds elapsed\")\n",
    "print(f\"{time()-hard_start:.2f} seconds to run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

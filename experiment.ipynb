{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "import glob\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = \"./data/data/data\"\n",
    "\n",
    "def load():\n",
    "    file_list = glob.glob(IMAGE_DIR + \"/*.jpg\")\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for fname in file_list:\n",
    "        with Image.open(fname) as img:\n",
    "            np_img = np.array(img).flatten()\n",
    "        label = int(os.path.split(fname)[-1].split('.')[0].split('_')[3])-1\n",
    "\n",
    "        X.append(np_img)\n",
    "        tempy = np.zeros(15)\n",
    "        tempy[label] = 1\n",
    "        Y.append(tempy)\n",
    "    X, Y = np.array(X), np.array(Y)\n",
    "    return(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data\n",
    "X, Y = load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WL_loss(H, Y, classifier):\n",
    "    true_y = np.array(Y)\n",
    "    return (sum([max(0, 1 - (true_y[classifier].reshape(1, true_y[classifier].shape[0]) @ np.array(wl.y_pred))/len(wl.y_pred)) for wl in H])/len(H))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(weights, best):\n",
    "    def f(x):\n",
    "        return 1/2*(1/(1-best.error_rate)) * x if x in best.miss_data else 1/2*(1/best.error_rate) * x\n",
    "    return np.array(map(f,weights)).tolist()\n",
    "\n",
    "def run(Weak_Learners, data, eval_set, H, weights):\n",
    "    for wl in Weak_Learners:\n",
    "        wl.miss_classify(data, eval_set)\n",
    "        wl.calc_error_rate(weights)\n",
    "    \n",
    "    best = Weak_Learners[0]\n",
    "    for wl in Weak_Learners:\n",
    "        if wl.error_rate < best.error_rate:\n",
    "            best = wl\n",
    "    \n",
    "    best.calc_voting_power()\n",
    "    H.append(best)\n",
    "    \n",
    "    weights = update_weights(weights, best)\n",
    "    \n",
    "    accuracy = H_accuracy(H, data, eval_set)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ratio: 10%\n",
      "Running ratio: 20%\n",
      "Running ratio: 30%\n",
      "Running ratio: 40%\n",
      "Running ratio: 50%\n",
      "Running ratio: 60%\n",
      "Running ratio: 70%\n",
      "Running ratio: 80%\n",
      "Running ratio: 90%\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "trainSizes = [x/10 for x in range(1,10)]\n",
    "hard_start = time()\n",
    "\n",
    "def print_dict(dictionary, sep=''):\n",
    "    for key in dictionary.keys():\n",
    "        new_sep = sep+'    '\n",
    "        if type(key) is int:\n",
    "            print(f\"Class {key}\")\n",
    "        else:\n",
    "            print(f\"{sep}{key}:\")\n",
    "        if type(dictionary[key]) is dict:\n",
    "            print_dict(dictionary[key], sep=new_sep)\n",
    "        elif type(dictionary[key]) is list:\n",
    "            val_str = \"\"\n",
    "            for i in range(len(dictionary[key])-1):\n",
    "                val_str += f\"{dictionary[key][i]:.3%}, \"\n",
    "            val_str += f\"{dictionary[key][-1]:.3%}\"\n",
    "            print(f\"{new_sep}{val_str}\")\n",
    "            print(f\"Average: {sum(dictionary[key])/len(dictionary[key]):.3%}\")\n",
    "        else:\n",
    "            print(f\"{new_sep}{dictionary[key]}\")\n",
    "\n",
    "def runner(pnum, ptracker, rcount, Xtrain, Ytrain, Xtest, Ytest, classifier):\n",
    "    H = []\n",
    "    Weak_Learners = []\n",
    "    for i in range(10):\n",
    "        model = ShallowTree()\n",
    "        model.fit(Xtrain, Ytrain)\n",
    "        Weak_Learners.append(WeakLearner(model, classifier))\n",
    "    weights = np.array([1/len(Xtrain) for _ in range(len(Xtrain))])\n",
    "    for r in range(10):\n",
    "        ptracker[rcount][pnum][\"accuracies\"][\"train\"].append(run(Weak_Learners, Xtrain, Ytrain, H, weights))\n",
    "        ptracker[rcount][pnum][\"accuracies\"][\"test\"].append(H_accuracy(H, Xtest, Ytest))\n",
    "#         ptracker[pnum][\"losses\"].append(WL_loss(H, Ytrain, classifier))\n",
    "\n",
    "def f(pnum, ptracker, rcount, split, X, Y):\n",
    "    for i in range(pnum):\n",
    "        ptracker[rcount][i] = {}\n",
    "        ptracker[rcount][i][\"accuracies\"] = {\"train\": [], \"test\": []}\n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, train_size=split, random_state = 2021)\n",
    "    Ytrain_classes = [classify(Ytrain, i) for i in range(15)]\n",
    "    Ytest_classes = [classify(Ytest, i) for i in range(15)]\n",
    "    jobs = []\n",
    "    for i in range(15):\n",
    "        proc = threading.Thread(target=runner, args=(i, ptracker, rcount, Xtrain, Ytrain_classes[i], Xtest, Ytest_classes[i], i), name=f\"Thread {i}\")\n",
    "        jobs.append(proc)\n",
    "        proc.start()\n",
    "    \n",
    "    for count,p in enumerate(jobs):\n",
    "        p.join()\n",
    "\n",
    "ptrackers = [{} for _ in trainSizes]\n",
    "ratio_threads = []\n",
    "for i,ratio in enumerate(trainSizes):\n",
    "    print(f\"Running ratio: {ratio:.0%}\")\n",
    "    proc = threading.Thread(target=f, args=(15, ptrackers, i, ratio, X, Y))\n",
    "    ratio_threads.append(proc)\n",
    "    proc.start()\n",
    "\n",
    "for i, proc in enumerate(ratio_threads):\n",
    "    proc.join()\n",
    "    print_dict(ptrackers[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here we test the performace of our model with different amounts of training data \n",
    "\"\"\"\n",
    "from time import time\n",
    "\n",
    "trainSizes = [x / 10 for x in range(1, 10, 1)] # Create a list of [0.5, ..., 0.9] If x < 0.5 we get an out of bounds error on the weights\n",
    "\n",
    "hard_start = time()\n",
    "\n",
    "for trainRatio in trainSizes:\n",
    "    start = time()\n",
    "    \n",
    "    Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, train_size=trainRatio, random_state=2021)\n",
    "    Ytrain_classes = []\n",
    "    Ytest_classes = []\n",
    "    for i in range(Ytrain.shape[1]):\n",
    "        Ytrain_i = classify(Ytrain, i)\n",
    "        Ytrain_classes.append(Ytrain_i)\n",
    "        Ytest_i = classify(Ytest, i)\n",
    "        Ytest_classes.append(Ytest_i)\n",
    "    \n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "    for i in range(Ytrain.shape[1]):\n",
    "        H = []\n",
    "        Weak_Learners = []\n",
    "        for _ in range(10):\n",
    "            model = ShallowTree()\n",
    "            model.fit(Xtrain, Ytrain_classes[0])\n",
    "            Weak_Learners.append(WeakLearner(model, 0))\n",
    "\n",
    "        weights = np.array([1/len(Xtrain) for _ in range(len(Xtrain))])\n",
    "        train_local_accuracies = []\n",
    "        test_local_accuracies = []\n",
    "        for r in range(10):\n",
    "            train_local_accuracies.append(run(Weak_Learners, Xtrain, Ytrain_classes[i], H, weights))\n",
    "            print(f\"Loss on run {r}: {WL_loss(H, Ytrain_classes, i):.3f}\")\n",
    "            test_local_accuracies.append(H_accuracy(H, Xtest, Ytest_classes[i]))\n",
    "\n",
    "        train_accuracies.append(sum(train_local_accuracies) / len(train_local_accuracies))\n",
    "        test_accuracies.append(sum(test_local_accuracies)/len(test_local_accuracies))\n",
    "        \n",
    "\n",
    "    print(f\"Ratio: {trainRatio:.2%}\\n\\t Train Accuracy: {sum(train_accuracies)/len(train_accuracies):.2%}\")\n",
    "    print(f\"Ratio: {trainRatio:.2%}\\n\\t Test Accuracy: {sum(test_accuracies)/len(test_accuracies):.2%}\")\n",
    "    print(f\"{time()-start:.2f} seconds elapsed\")\n",
    "    \n",
    "print(f\"{time()-hard_start:.2f} seconds to run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13500, 15)\n",
      "(1500, 15)\n"
     ]
    }
   ],
   "source": [
    "print(Ytrain.shape)\n",
    "print(Ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent correct with training set and tree size 2: 82.10%\n",
      "Percent correct with test set and tree size 2: 82.49%\n",
      "685.31 seconds elapsed\n",
      "Percent correct with training set and tree size 3: 81.15%\n",
      "Percent correct with test set and tree size 3: 81.34%\n",
      "770.76 seconds elapsed\n",
      "Percent correct with training set and tree size 4: 80.59%\n",
      "Percent correct with test set and tree size 4: 80.99%\n",
      "848.00 seconds elapsed\n",
      "Percent correct with training set and tree size 5: 80.21%\n",
      "Percent correct with test set and tree size 5: 80.79%\n",
      "872.08 seconds elapsed\n",
      "Percent correct with training set and tree size 6: 79.90%\n",
      "Percent correct with test set and tree size 6: 80.59%\n",
      "962.80 seconds elapsed\n",
      "Percent correct with training set and tree size 7: 79.61%\n",
      "Percent correct with test set and tree size 7: 80.38%\n",
      "1051.88 seconds elapsed\n",
      "Percent correct with training set and tree size 8: 79.32%\n",
      "Percent correct with test set and tree size 8: 80.17%\n",
      "1139.44 seconds elapsed\n",
      "Percent correct with training set and tree size 9: 79.07%\n",
      "Percent correct with test set and tree size 9: 79.97%\n",
      "1230.19 seconds elapsed\n",
      "7560.57 seconds to run\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Now we vary the size of the trees\n",
    "We use 80% train, 20% test (The standard)\n",
    "\"\"\"\n",
    "hard_start = time()\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, train_size=0.8, random_state=2021)\n",
    "Ytrain_classes = []\n",
    "Ytest_classes = []\n",
    "\n",
    "\n",
    "for treeSize in range(2, 10):\n",
    "    start = time()\n",
    "    for i in range(Ytrain.shape[1]):\n",
    "        Ytrain_i = classify(Ytrain, i)\n",
    "        Ytrain_classes.append(Ytrain_i)\n",
    "        Ytest_i = classify(Ytest, i)\n",
    "        Ytest_classes.append(Ytest_i)\n",
    "\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "    for i in range(Ytrain.shape[1]):\n",
    "        H_train = []\n",
    "        H_test =[]\n",
    "        Weak_Learners = []\n",
    "        for _ in range(10):\n",
    "            model = ShallowTree(treeSize)\n",
    "            model.fit(Xtrain, Ytrain_classes[0])\n",
    "            Weak_Learners.append(WeakLearner(model, 0))\n",
    "\n",
    "        weights = np.array([1/len(Xtrain) for _ in range(len(Xtrain))])\n",
    "        local_accuracies = []\n",
    "        \n",
    "        for r in range(10):\n",
    "            train_local_accuracies.append(run(Weak_Learners, Xtrain, Ytrain_classes[i], H_train, weights))\n",
    "            test_local_accuracies.append(run(Weak_Learners, Xtest, Ytest_classes[i], H_test, weights))\n",
    "\n",
    "        train_accuracies.append(sum(train_local_accuracies) / len(train_local_accuracies))\n",
    "        test_accuracies.append(sum(test_local_accuracies)/len(test_local_accuracies))\n",
    "\n",
    "    print(f\"Percent correct with training set and tree size {treeSize}: {sum(train_accuracies)/len(train_accuracies):.2%}\")\n",
    "    print(f\"Percent correct with test set and tree size {treeSize}: {sum(test_accuracies)/len(test_accuracies):.2%}\")\n",
    "    print(f\"{time()-start:.2f} seconds elapsed\")\n",
    "print(f\"{time()-hard_start:.2f} seconds to run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "import glob\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = \"./data/Chinese_MNIST/data/data\"\n",
    "\n",
    "def load():\n",
    "    file_list = glob.glob(IMAGE_DIR + \"/*.jpg\")\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for fname in file_list:\n",
    "        with Image.open(fname) as img:\n",
    "            np_img = np.array(img).flatten()\n",
    "        label = int(os.path.split(fname)[-1].split('.')[0].split('_')[3])-1\n",
    "\n",
    "        X.append(np_img)\n",
    "        Y.append(label)\n",
    "\n",
    "    return(np.array(X), np.array(Y))\n",
    "\n",
    "def get_dataset(i):\n",
    "    X = None\n",
    "    Y = None \n",
    "    if i == 0: #Sign Language MNIST \n",
    "        train_df = pd.read_csv(\"./data/Sign_Language_MNIST/sign_mnist_train.csv\")\n",
    "        test_df = pd.read_csv(\"./data/Sign_Language_MNIST/sign_mnist_test.csv\")\n",
    "        \n",
    "        Ytrain = train_df['label']\n",
    "        Ytest = test_df['label']\n",
    "        del train_df['label']\n",
    "        del test_df['label']\n",
    "        \n",
    "        Xtrain = train_df.values\n",
    "        Xtest = test_df.values\n",
    "        X = np.append(Xtrain, Xtest, 0)\n",
    "        Y = np.append(Ytrain, Ytest, 0)\n",
    "        \n",
    "    elif i == 1:#Chinese MNIST \n",
    "        X, Y = load()\n",
    "        \n",
    "    elif i == 2: #Fashion MNIST\n",
    "        (Xtrain, Ytrain), (Xtest, Ytest) = fashion_mnist.load_data()\n",
    "        Xtrain = Xtrain.reshape((len(Xtrain), np.prod(Xtrain.shape[1:])))\n",
    "        Xtest = Xtest.reshape((len(Xtest), np.prod(Xtest.shape[1:])))\n",
    "        X = np.append(Xtrain, Xtest, 0)\n",
    "        Y = np.append(Ytrain, Ytest, 0)\n",
    "        \n",
    "    return (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here we test the performace of our model with different amounts of training data\n",
    "\"\"\"\n",
    "from time import time\n",
    "\n",
    "all_train_accuracy_ratio = list()\n",
    "all_testing_accuracy_ratio = list()\n",
    "\n",
    "batches = [x / 10 for x in range(1, 11, 1)]\n",
    "\n",
    "for batch_mult in batches:\n",
    "    batch_train_accuracy = list()\n",
    "    batch_test_accuracy = list()\n",
    "    \n",
    "    for dataset in range(3):\n",
    "        hard_start = time()\n",
    "\n",
    "        X, Y = get_dataset(dataset)\n",
    "        trainSizes = [x / 10 for x in range(1, 10, 1)] # Create a list of [0.5, ..., 0.9] If x < 0.5 we get an out of bounds error on the weights\n",
    "\n",
    "        train_accuracy = []\n",
    "        test_accuracy = []\n",
    "\n",
    "        for trainRatio in trainSizes:\n",
    "            start = time()\n",
    "            print(f\"Dataset: {dataset+1}; Batch Size: len(X)*{batch_mult}; Ratio: {trainRatio:.2%}\")\n",
    "            \n",
    "            Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, train_size=trainRatio, random_state=2021)\n",
    "\n",
    "            model = Boost(n_estimators=500, base_learner=ShallowTree()).update_fit(Xtrain,Ytrain, verbose=100, batch_size=round(len(Xtrain)*batch_mult))\n",
    "\n",
    "            train_acc = model.accuracy(model.predict(Xtrain),Ytrain)\n",
    "            train_accuracy.append(train_acc)\n",
    "            print(f\"Ratio: {trainRatio:.2%}\\n\\t Train Accuracy: {train_acc:.2%}\")\n",
    "            test_acc = model.accuracy(model.predict(Xtest),Ytest)\n",
    "            test_accuracy.append(test_acc)\n",
    "            print(f\"Ratio: {trainRatio:.2%}\\n\\t Test Accuracy: {test_acc:.2%}\")\n",
    "            print(f\"{time()-start:.2f} seconds elapsed\")\n",
    "\n",
    "        batch_train_accuracy.append(train_accuracy)\n",
    "        batch_test_accuracy.append(test_accuracy)\n",
    "        print(f\"{time()-hard_start:.2f} seconds to run\")\n",
    "    \n",
    "    all_train_accuracy_ratio.append(batch_train_accuracy)\n",
    "    all_testing_accuracy_ratio.append(batch_test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 0; Batch Size: len(X)*0.1; Treesize: 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-e9d6be8dbef6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Dataset: {dataset}; Batch Size: len(X)*{batch_mult}; Treesize: {treeSize}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBoost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m250\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_learner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mShallowTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtreeSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_mult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mYtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Stochastic-Gradient-Boosting-and-Adaboost\\functions.py\u001b[0m in \u001b[0;36mupdate_fit\u001b[1;34m(self, X, Y, verbose, batch_size)\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m                 \u001b[0mlocal_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_samples_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_samples_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m             \u001b[0mlocal_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mboost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mestimator_error\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Stochastic-Gradient-Boosting-and-Adaboost\\functions.py\u001b[0m in \u001b[0;36mboost\u001b[1;34m(self, X, Y, weights, indices, visible)\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ohad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    888\u001b[0m         \"\"\"\n\u001b[0;32m    889\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 890\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m    891\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ohad\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    373\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Now we vary the size of the trees\n",
    "We use 80% train, 20% test (The standard)\n",
    "\"\"\"\n",
    "all_train_accuracy_tree = list()\n",
    "all_testing_accuracy_tree = list()\n",
    "\n",
    "batches = [x / 10 for x in range(1, 11, 1)]\n",
    "\n",
    "for batch_mult in batches:\n",
    "    batch_train_accuracy = list()\n",
    "    batch_test_accuracy = list()\n",
    "    \n",
    "    for dataset in range(3):\n",
    "        hard_start = time()\n",
    "        X, Y = get_dataset(dataset)\n",
    "\n",
    "        Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, train_size=0.8, random_state=2021)\n",
    "\n",
    "        train_accuracy = []\n",
    "        test_accuracy = []\n",
    "\n",
    "        for treeSize in [1, 3, 6, 11, 21, 41, 81, 161]:\n",
    "            start = time()\n",
    "            print(f\"Dataset: {dataset+1}; Batch Size: len(X)*{batch_mult}; Treesize: {treeSize}\")\n",
    "            model = Boost(n_estimators=250, base_learner=ShallowTree(treeSize)).update_fit(Xtrain, Ytrain, verbose=50, batch_size=round(len(Xtrain)*batch_mult))\n",
    "\n",
    "            train_acc = model.accuracy(model.predict(Xtrain),Ytrain)\n",
    "            train_accuracy.append(train_acc)\n",
    "            test_acc = model.accuracy(model.predict(Xtest),Ytest)\n",
    "            test_accuracy.append(test_acc)\n",
    "\n",
    "            print(f\"Percent correct with training set and tree size {treeSize}: {train_acc:.2%}\")\n",
    "            print(f\"Percent correct with test set and tree size {treeSize}: {test_acc:.2%}\")\n",
    "            print(f\"{time()-start:.2f} seconds elapsed\")\n",
    "\n",
    "        batch_train_accuracy.append(train_accuracy)\n",
    "        batch_test_accuracy.append(test_accuracy)\n",
    "        print(f\"{time()-hard_start:.2f} seconds to run\")\n",
    "        \n",
    "    all_train_accuracy_tree.append(batch_train_accuracy)\n",
    "    all_testing_accuracy_tree.append(batch_test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
